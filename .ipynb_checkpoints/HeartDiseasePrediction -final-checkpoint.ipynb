{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "268b7626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b71ac302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
       "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
       "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
       "3   61    1   0       148   203    0        1      161      0      0.0      2   \n",
       "4   62    0   0       138   294    1        1      106      0      1.9      1   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   2     3       0  \n",
       "1   0     3       0  \n",
       "2   0     3       0  \n",
       "3   1     3       0  \n",
       "4   3     2       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('heart1.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cced0db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_mapping = {'1': 'Heart Disease', '0': 'No Heart Disease'}\n",
    "dataset['target'] = dataset['target'].replace(target_mapping)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(data=dataset, x='target')\n",
    "plt.title('Heart Disease vs No Heart Disease')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b94d58d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArcAAAIhCAYAAABUopIpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABQ2klEQVR4nO3deVgV9f///8eRHQQUkC0Ryd1ATS2DFvcdTa2sfGduqeXSm9SvZn5SNJMst9LSFhWXivpUWpm5L2lqoaVpWqm5FoQrCCEozO+PfpxPRxYRkYPj/XZdc13Oa14z85xz5hweznmdORbDMAwBAAAAJlDB3gUAAAAApYVwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwi0LFx8fLYrFo586dBS6Pjo5W9erVy7aof1m5cqViY2OL3b9v376yWCzWycPDQ9WrV1fXrl21cOFCZWVl5VunRYsWatGiRekVfYvKe+zvuOMO5eTk5FtusVg0bNiwUttfixYtFB4eXuCy06dPy2KxXNO5U9qmTJmi5cuXF7v/v89bBwcHVa5cWQ0bNtTgwYO1Y8eOfP2PHj0qi8Wi+Pj40iu6nDp79qwee+wx+fv7y2KxqFu3bvYuqVRs2rRJFotFmzZtsncpN0Tfvn2L9fcjOztbTz/9tIKCguTg4KBGjRrd8NpK4lZ6zd0MHO1dAFBSK1eu1JtvvnlNIcXNzU0bNmyQJGVmZurEiRP6+uuvNXDgQE2fPl2rVq1S1apVrf3feuut0i77lrZ//37Fx8drwIAB9i7FrqZMmaKHH374moLYww8/rJEjR8owDKWlpWnfvn1avHix3nnnHT377LN6/fXXrX2DgoK0fft21ahR4wZUX7689NJLWrZsmRYsWKAaNWrIx8fH3iWhFM2dO1dvv/22Zs+erSZNmqhixYr2Lgk3AcItbjp///233N3dS7RuhQoVdM8999i0Pfnkk+rXr5+io6P18MMP21wJq1+//nXViv/j4eGhxo0ba8KECerVq5fc3NzsXVKZy8zMLPFxBwQE2Jy77du3V0xMjAYNGqQ33nhDdevW1TPPPCNJcnFxyXeem9W+fftUo0YN/ec//ymV7RmGoYsXL96S52d5tG/fPrm5uZXqJzswP4YloFQZhqG33npLjRo1kpubmypXrqyHH35Yv//+u02/tWvX6sEHH1TVqlXl6uqqmjVravDgwTp9+rRNv9jYWFksFv3www96+OGHVblyZdWoUUN9+/bVm2++Kcn2I9ujR4+WqO527dpp4MCB+u677/TNN99Y2wsaljB37lw1bNhQFStWlKenp+rWrasXXnjBpk9ycrIGDx6sqlWrytnZWWFhYZo4caIuX75s02/ixIlq1qyZfHx85OXlpcaNG2v+/PkyDMOm34YNG9SiRQv5+vrKzc1N1apV00MPPaS///7b2ic7O1uTJ09W3bp15eLioipVqqhfv346depUkcc+a9YsWSwWHTp0KN+yMWPGyNnZ2fq8/Pjjj4qOjpa/v79cXFwUHByszp076+TJk0XuI8/UqVP1xx9/2FxlLMzx48f1xBNPWPdVr149TZ8+Xbm5ucXa17Uq7eesevXqio6O1meffaY777xTrq6umjhxoiwWizIyMrRo0SLreVvSoS8ODg6aM2eO/Pz89Nprr1nbC/qI9NSpUxo0aJBCQkKs58e9996rdevW2Wxz3bp1at26tby8vOTu7q57771X69evt+lz6NAh9evXT7Vq1ZK7u7tuu+02denSRXv37rXpl5ubq8mTJ6tOnTpyc3NTpUqV1KBBg3zP/8GDB9WrVy+b5zrv9V2YvGNct26dDhw4YH0s8z7GP3v2rIYMGaLbbrtNzs7Ouv322zVu3Lh8w4/yhsTMmzdP9erVk4uLixYtWlTofvOe1xUrVujOO++Um5ub6tWrpxUrVkj6ZzhXvXr15OHhobvvvjvfsK6dO3fqscceU/Xq1eXm5qbq1avr8ccf17Fjx4o83n+v37VrV/n4+MjV1VV33nmnPv74Y5s+f//9t0aNGqWwsDC5urrKx8dHTZs21Ycffljktk+dOqUhQ4aofv36qlixovz9/dWqVStt2bLFpl/eYz9t2jTNmDFDYWFhqlixoiIjIwscJhMfH686depYn9vFixcX61gtFovee+89ZWZmWp/fvHO6uH9r8oYobd++XVFRUdbHfOHChZKkr776So0bN5a7u7siIiK0atUqm/WLe64XpjjndnFfJyg+rtziqnJycvL9gZeU74+5JA0ePFjx8fF69tlnNXXqVJ09e1aTJk1SVFSU9uzZo4CAAEnS4cOHFRkZqaeeekre3t46evSoZsyYofvuu0979+6Vk5OTzXZ79Oihxx57TE8//bQyMjIUHh6ujIwMffLJJ9q+fbu1X1BQUImPs2vXrnrrrbf0zTff6IEHHiiwT0JCgoYMGaLhw4dr2rRpqlChgg4dOqT9+/db+yQnJ+vuu+9WhQoVNH78eNWoUUPbt2/X5MmTdfToUeubqvTPH4nBgwerWrVqkqQdO3Zo+PDh+uOPPzR+/Hhrn86dO+v+++/XggULVKlSJf3xxx9atWqVsrOz5e7urtzcXD344IPasmWLRo8eraioKB07dkwTJkxQixYttHPnzkKvRD3xxBMaM2aM4uPjNXnyZGt7Tk6Oli5dqi5dusjPz08ZGRlq27atwsLC9OabbyogIEDJycnauHGjLly4UKzHODIyUt27d9fUqVM1aNCgQj9CPnXqlKKiopSdna2XXnpJ1atX14oVKzRq1CgdPny42MNFCjpvCxrzW9rPWZ4ffvhBBw4c0P/8z/8oLCxMHh4e6tatm1q1aqWWLVvqxRdflCR5eXkV63gK4ubmpjZt2ighIUEnT560GVbzb71799YPP/ygl19+WbVr19b58+f1ww8/6MyZM9Y+S5cu1ZNPPqkHH3xQixYtkpOTk95++221b99eq1evVuvWrSVJf/75p3x9ffXKK6+oSpUqOnv2rBYtWqRmzZrpxx9/VJ06dSRJr776qmJjY/U///M/euCBB3Tp0iX98ssvOn/+vHWf+/fvV1RUlKpVq6bp06crMDBQq1ev1rPPPqvTp09rwoQJBR5P3tCLIUOGKDU1Ve+//76kfz5tuXjxolq2bKnDhw9r4sSJatCggbZs2aK4uDjt3r1bX331lc22li9fri1btmj8+PEKDAyUv79/kY/5nj17NHbsWI0bN07e3t6aOHGievToobFjx2r9+vWaMmWKLBaLxowZo+joaB05csT6+jt69Kjq1Kmjxx57TD4+PkpKStLcuXN11113af/+/fLz8yt0vxs3blSHDh3UrFkzzZs3T97e3kpISNCjjz6qv//+W3379pUkjRgxQkuWLNHkyZN15513KiMjQ/v27bN5rgty9uxZSdKECRMUGBio9PR0LVu2TC1atND69evz/SfszTffVN26dTVr1ixJ0osvvqhOnTrpyJEj8vb2lvRPsO3Xr58efPBBTZ8+XampqYqNjVVWVpYqVCj6+tr27dv10ksvaePGjdbhZHlDbYr7t0b65/Xdr18/jR49WlWrVtXs2bPVv39/nThxQp988oleeOEFeXt7a9KkSerWrZt+//13BQcHSyr+uV6Q4p7bxXmd4BoZQCEWLlxoSCpyCg0Ntfbfvn27IcmYPn26zXZOnDhhuLm5GaNHjy5wP7m5ucalS5eMY8eOGZKMzz//3LpswoQJhiRj/Pjx+dYbOnSocS2ncJ8+fQwPD49Clx84cMCQZDzzzDPWtubNmxvNmze3zg8bNsyoVKlSkfsZPHiwUbFiRePYsWM27dOmTTMkGT///HOB6+Xk5BiXLl0yJk2aZPj6+hq5ubmGYRjGJ598Ykgydu/eXeg+P/zwQ0OS8emnn9q0JyYmGpKMt956q8iae/ToYVStWtXIycmxtq1cudKQZHz55ZeGYRjGzp07DUnG8uXLi9xWQf792P/yyy+Gg4ODMXLkSOtyScbQoUOt888//7whyfjuu+9stvPMM88YFovF+PXXX4vcX/Pmza967k6YMMHav7SfM8MwjNDQUMPBwaHAWj08PIw+ffoUeQz/duXjc6UxY8bYPF5HjhwxJBkLFy609qlYsaIRExNT6DYyMjIMHx8fo0uXLjbtOTk5RsOGDY2777670HUvX75sZGdnG7Vq1TKee+45a3t0dLTRqFGjIo+tffv2RtWqVY3U1FSb9mHDhhmurq7G2bNni1y/efPmxh133GHTNm/ePEOS8fHHH9u0T5061ZBkrFmzxtomyfD29r7qfvKEhoYabm5uxsmTJ61tu3fvNiQZQUFBRkZGhrV9+fLlhiTjiy++KHR7ly9fNtLT0w0PDw/j9ddft7Zv3LjRkGRs3LjR2la3bl3jzjvvNC5dumSzjejoaCMoKMj6+g0PDze6detWrOMpyuXLl41Lly4ZrVu3Nrp3725tzzu/IiIijMuXL1vbv//+e0OS8eGHHxqG8c+5ExwcbDRu3NjmtXH06FHDycnJ5u9HYQp6376WvzV57wU7d+60tp05c8ZwcHAw3NzcjD/++MPanvc8vvHGG0U+JgWd6wW95op7bhfndYJrw7AEXNXixYuVmJiYb7rvvvts+q1YsUIWi0VPPPGELl++bJ0CAwPVsGFDm2/9pqSk6Omnn1ZISIgcHR3l5OSk0NBQSdKBAwfy1fDQQw/d0GOUCr4SfaW7775b58+f1+OPP67PP/883zAK6Z/HoWXLlgoODrZ5HDp27ChJ2rx5s7Xvhg0b1KZNG3l7e8vBwUFOTk4aP368zpw5o5SUFElSo0aN5OzsrEGDBmnRokX5PnbL22elSpXUpUsXm302atRIgYGBV/3Gdb9+/XTy5Embj6gXLlyowMBAa901a9ZU5cqVNWbMGM2bN8/mavW1qFOnjgYMGKA5c+bo+PHjBfbZsGGD6tevr7vvvtumvW/fvjIMw3oVpyg1atQo8Ly98mN4qfSfszwNGjRQ7dq1r1rr9SruuZt3dX7Hjh26dOmSzfJt27bp7Nmz6tOnj81jkJubqw4dOigxMVEZGRmS/rkiPmXKFNWvX1/Ozs5ydHSUs7OzDh48aPP6vfvuu7Vnzx4NGTJEq1evVlpams0+L168qPXr16t79+5yd3e32W+nTp108eLFAj/mvpoNGzbIw8NDDz/8sE173pXNK4dZtGrVSpUrVy729hs1aqTbbrvNOl+vXj1J/3wE/u/vA+S1/3vIQXp6usaMGaOaNWvK0dFRjo6OqlixojIyMgp878tz6NAh/fLLL9axxVc+VklJSfr1118l/fO4f/3113r++ee1adMmZWZmFvvY5s2bp8aNG8vV1dX63rx+/foCa+vcubMcHBys8w0aNLA53l9//VV//vmnevXqJYvFYu0XGhqqqKioYtd0pWv5WyP9c5W/SZMm1nkfHx/5+/urUaNG1iu0UsHPV3HP9Stdy7l9tdcJrh3hFldVr149NW3aNN+U97FTnr/++kuGYSggIEBOTk42044dO6xBMDc3V+3atdNnn32m0aNHa/369fr++++tL/SC3oivZ7hBceW9of37ze5KvXv31oIFC3Ts2DE99NBD8vf3V7NmzbR27Vprn7/++ktffvllvsfgjjvukCTr4/D999+rXbt2kqR3331X3377rRITEzVu3DhJ//c41KhRQ+vWrZO/v7+GDh2qGjVqqEaNGjbjsf766y+dP39ezs7O+fabnJxcYAj/t44dOyooKMj68fu5c+f0xRdf6Mknn7T+8fL29tbmzZvVqFEjvfDCC7rjjjsUHBysCRMm5AtKVxMbGysHBwfrx/JXOnPmTIHPed5zc7WPVyXJ1dW1wPO2YcOG+fqW9nOWpyzOW6l45+5HH32kPn366L333lNkZKR8fHz05JNPKjk5WdI/j4H0z10Zrnwcpk6dKsMwrB9bjxgxQi+++KK6deumL7/8Ut99950SExPVsGFDm8dg7NixmjZtmnbs2KGOHTvK19dXrVu3to5DPXPmjC5fvqzZs2fn22enTp0k6arnbkHOnDmjwMBAm0AlSf7+/nJ0dMx3/lzr83TlcBpnZ+ci2y9evGht69Wrl+bMmaOnnnpKq1ev1vfff6/ExERVqVKlyBCa9/yMGjUq32M1ZMgQSf/3WL3xxhsaM2aMli9frpYtW8rHx0fdunXTwYMHizyuGTNm6JlnnlGzZs306aefaseOHUpMTFSHDh0KrM3X19dm3sXFRdL/vQ7yHufAwMB86xbUVlzF/VuTp6DhT87OzsV6vop7rl/pWs7tq71OcO0Yc4tS4+fnJ4vFoi1btljf5P4tr23fvn3as2eP4uPj1adPH+vygr7QlOfKP1I3whdffCFJV/1yT79+/dSvXz9lZGTom2++0YQJExQdHa3ffvtNoaGh8vPzU4MGDfTyyy8XuH5eAElISJCTk5NWrFghV1dX6/KC7n96//336/7771dOTo527typ2bNnKyYmRgEBAXrsscfk5+cnX1/ffF+GyOPp6VnkMTk4OKh379564403dP78eX3wwQfKyspSv379bPpFREQoISFBhmHop59+Unx8vCZNmiQ3Nzc9//zzRe7j34KCghQTE6NXXnlFI0eOzLfc19dXSUlJ+dr//PNPSSpyXGJJ3IjnTCqb8zYzM1Pr1q1TjRo1Ch1vK/1zjLNmzdKsWbN0/PhxffHFF3r++eeVkpKiVatWWR/T2bNnF3qnhbxxjHljc6dMmWKz/PTp06pUqZJ13tHRUSNGjNCIESN0/vx5rVu3Ti+88ILat2+vEydOqHLlytZzb+jQoQXuMyws7FoeDkn/nD/fffedDMOweQ5SUlJ0+fLlfOdPWTxPkpSamqoVK1ZowoQJNq+XrKws638cCpNX89ixY9WjR48C++SN//Tw8NDEiRM1ceJE/fXXX9aruF26dNEvv/xS6D6WLl2qFi1aaO7cuTbtxR1Tf6W88Jv3H6h/K6ituIr7t6Y0FPdcv9K1nNtXe52U9O5AtzLCLUpNdHS0XnnlFf3xxx/q2bNnof3y/pBc+Qb09ttvX9P+/n2V4Hpv27N27Vq99957ioqKyjfcojAeHh7q2LGjsrOz1a1bN/38888KDQ1VdHS0Vq5cqRo1ahT5UafFYpGjo6PNx3qZmZlasmRJoes4ODioWbNmqlu3rt5//3398MMPeuyxxxQdHa2EhATl5OSoWbNmxT/wf+nXr59effVVffjhh4qPj1dkZKTq1q1baO0NGzbUzJkzFR8frx9++OGa9zdmzBi98847BYbi1q1bKy4uTj/88IMaN25sbV+8eLEsFotatmx5zfsryo18zgri4uJyTR8VFyYnJ0fDhg3TmTNnFBcXV+z1qlWrpmHDhmn9+vX69ttvJUn33nuvKlWqpP3791/1tksWiyXf6/err77SH3/8oZo1axa4TqVKlfTwww/rjz/+UExMjI4ePar69eurZcuW+vHHH9WgQQPrlbPr1bp1a3388cdavny5unfvbm3P+5Z+3hfjyprFYpFhGPkeu/fee6/ALzr+W506dVSrVi3t2bMnX9AqSkBAgPr27as9e/Zo1qxZRd5KsaDn9aefftL27dsVEhJS7H3+u+agoCB9+OGHGjFihPW9/9ixY9q2bVuRnzQUpbh/a0pDSc51SXJ3dy/RuV3Y6wTXhnCLUnPvvfdq0KBB6tevn3bu3KkHHnhAHh4eSkpK0tatWxUREaFnnnlGdevWVY0aNfT888/LMAz5+Pjoyy+/tPlovzgiIiIk/XN7qY4dO8rBweGqbyK5ubnW4Q9ZWVk6fvy4vv76a3388ceqV69evlvqXGngwIFyc3PTvffeq6CgICUnJysuLk7e3t666667JEmTJk3S2rVrFRUVpWeffVZ16tTRxYsXdfToUa1cuVLz5s1T1apV1blzZ82YMUO9evXSoEGDdObMGU2bNi3fG+m8efO0YcMGde7cWdWqVdPFixe1YMECSVKbNm0kSY899pjef/99derUSf/973919913y8nJSSdPntTGjRv14IMP2vyRL0jdunUVGRmpuLg4nThxQu+8847N8hUrVuitt95St27ddPvtt8swDH322Wc6f/682rZtW+S2C+Ll5aVx48bpueeey7fsueee0+LFi9W5c2dNmjRJoaGh+uqrr/TWW2/pmWeeKfVxrKX9nF1NRESENm3apC+//FJBQUHy9PQs8lvX0j8fxe7YsUOGYejChQvWH3HYs2ePnnvuOQ0cOLDQdVNTU9WyZUv16tVLdevWlaenpxITE7Vq1SrrVcCKFStq9uzZ6tOnj86ePauHH35Y/v7+OnXqlPbs2aNTp05Zr+hFR0crPj5edevWVYMGDbRr1y699tpr+a4cd+nSReHh4WratKmqVKmiY8eOadasWQoNDVWtWrUkSa+//rruu+8+3X///XrmmWdUvXp1XbhwQYcOHdKXX35ZrPHVV3ryySf15ptvqk+fPjp69KgiIiK0detWTZkyRZ06dbK+bsqal5eXHnjgAb322mvy8/NT9erVtXnzZs2fP7/Iq4B53n77bXXs2FHt27dX3759ddttt+ns2bM6cOCAfvjhB/3v//6vJKlZs2aKjo5WgwYNVLlyZR04cEBLlixRZGRkkVcBo6Oj9dJLL2nChAlq3ry5fv31V02aNElhYWEF3nnkaipUqKCXXnpJTz31lLp3766BAwfq/Pnzio2Nva5hCcX9W1MainuuF6S453ZxXie4Rvb5HhtuBnl3S0hMTCxweefOnQv8tuuCBQuMZs2aGR4eHoabm5tRo0YN48knn7T5tur+/fuNtm3bGp6enkblypWNRx55xDh+/Hi+b7Hn3S3h1KlT+faTlZVlPPXUU0aVKlUMi8ViSDKOHDlS6PH06dPH5tvybm5uRrVq1YwuXboYCxYsMLKysvKtc+XdEhYtWmS0bNnSCAgIMJydnY3g4GCjZ8+exk8//WSz3qlTp4xnn33WCAsLM5ycnAwfHx+jSZMmxrhx44z09HSbx6pOnTqGi4uLcfvttxtxcXHG/PnzbY5l+/btRvfu3Y3Q0FDDxcXF8PX1NZo3b57vG9iXLl0ypk2bZjRs2NBwdXU1KlasaNStW9cYPHiwcfDgwUIfl3975513rI/Nld/w/eWXX4zHH3/cqFGjhuHm5mZ4e3sbd999txEfH3/V7RZ2p4qsrCwjLCyswLsBHDt2zOjVq5fh6+trODk5GXXq1DFee+01mzs6FKagb9DnOXXqVL7zLK+9tJ4zw/jnW/WdO3cusIbdu3cb9957r+Hu7m5IsjnHCvLv87ZChQqGl5eXERERYQwaNMjYvn17vv5XfnP74sWLxtNPP200aNDA8PLyMtzc3Iw6deoYEyZMsPl2v2EYxubNm43OnTsbPj4+hpOTk3HbbbcZnTt3Nv73f//X2ufcuXPGgAEDDH9/f8Pd3d247777jC1btuR7vUyfPt2Iiooy/Pz8DGdnZ6NatWrGgAEDjKNHj+art3///sZtt91mODk5GVWqVDGioqKMyZMnF/m4GEbhz/WZM2eMp59+2ggKCjIcHR2N0NBQY+zYscbFixfzPbZF3YniSoU9rwVtJ+95eO2116xtJ0+eNB566CGjcuXKhqenp9GhQwdj3759RmhoqM0dNAq6W4JhGMaePXuMnj17Gv7+/oaTk5MRGBhotGrVypg3b561z/PPP280bdrUqFy5svU8fe6554zTp08XeWxZWVnGqFGjjNtuu81wdXU1GjdubCxfvtzo06ePzXt9Qcf178fhytfWe++9Z9SqVctwdnY2ateubSxYsCDfNgtT1F1uivO3prDzo7jPY3HP9YLulpDXfrVzu7ivExSfxTCK8TVbAAAA4CbA3RIAAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAY/4qB/buz/559/ytPTs8x+hhEAAADFZ/z/P2ITHBysChUKvz5LuNU/v1dfkp8WBAAAQNk6ceJEkb8SR7iV5OnpKemfB8vLy8vO1QAAAOBKaWlpCgkJsea2whBuJetQBC8vL8ItAABAOXa1IaR8oQwAAACmQbgFAACAaRBuAQAAYBqMuQUAALe8nJwcXbp0yd5l3NIcHBzk6Oh43bdlJdwCAIBbWnp6uk6ePCnDMOxdyi3P3d1dQUFBcnZ2LvE2CLcAAOCWlZOTo5MnT8rd3V1VqlThx5zsxDAMZWdn69SpUzpy5Ihq1apV5A81FIVwCwAAblmXLl2SYRiqUqWK3Nzc7F3OLc3NzU1OTk46duyYsrOz5erqWqLt8IUyAABwy+OKbflQ0qu1NtsohToAAACAcoFwCwAAANNgzC0AAMAVeo3fVKb7+2BSizLd341SvXp1xcTEKCYmxm41cOUWAADgJtS3b19ZLJZ806FDh+xdml1x5RYAAOAm1aFDBy1cuNCmrUqVKnaqpnzgyi0AAMBNysXFRYGBgTaTg4ODvvzySzVp0kSurq66/fbbNXHiRF2+fNm6nsVi0dtvv63o6Gi5u7urXr162r59uw4dOqQWLVrIw8NDkZGROnz4sHWdw4cP68EHH1RAQIAqVqyou+66S+vWrSuyvtTUVA0aNEj+/v7y8vJSq1attGfPnhv2eEiEWwAAAFNZvXq1nnjiCT377LPav3+/3n77bcXHx+vll1+26ffSSy/pySef1O7du1W3bl316tVLgwcP1tixY7Vz505J0rBhw6z909PT1alTJ61bt04//vij2rdvry5duuj48eMF1mEYhjp37qzk5GStXLlSu3btUuPGjdW6dWudPXv2hh0/wxIAAABuUitWrFDFihWt8x07dtRff/2l559/Xn369JEk3X777XrppZc0evRoTZgwwdq3X79+6tmzpyRpzJgxioyM1Isvvqj27dtLkv773/+qX79+1v4NGzZUw4YNrfOTJ0/WsmXL9MUXX9iE4DwbN27U3r17lZKSIhcXF0nStGnTtHz5cn3yyScaNGhQKT4S/4dwCwAAcJNq2bKl5s6da5338PBQzZo1lZiYaHOlNicnRxcvXtTff/8td3d3SVKDBg2sywMCAiRJERERNm0XL15UWlqavLy8lJGRoYkTJ2rFihX6888/dfnyZWVmZhZ65XbXrl1KT0+Xr6+vTXtmZqbNcIfSRrgFAAC4SeWF2X/Lzc3VxIkT1aNHj3z9//2Ttk5OTtZ/5/1CW0Ftubm5kqT/9//+n1avXq1p06apZs2acnNz08MPP6zs7OwCa8vNzVVQUJA2bdqUb1mlSpWKd4AlQLgFAAAwkcaNG+vXX3/NF3qv15YtW9S3b191795d0j9jcI8ePVpkHcnJyXJ0dFT16tVLtZaiEG6BMvbbtL72LgFlqPaoeHuXAOAWM378eEVHRyskJESPPPKIKlSooJ9++kl79+7V5MmTS7zdmjVr6rPPPlOXLl1ksVj04osvWq/qFqRNmzaKjIxUt27dNHXqVNWpU0d//vmnVq5cqW7duqlp06YlrqUohFsAAIAr3My/GNa+fXutWLFCkyZN0quvvionJyfVrVtXTz311HVtd+bMmerfv7+ioqLk5+enMWPGKC0trdD+FotFK1eu1Lhx49S/f3+dOnVKgYGBeuCBB6xjfG8Ei2EYxg3b+k0iLS1N3t7eSk1NlZeXl73Lgclx5fbWwpVboHy7ePGijhw5orCwMJvxqLCPop6P4uY17nMLAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAAwDQItwAAADCNchNu4+LiZLFYFBMTY20zDEOxsbEKDg6Wm5ubWrRooZ9//tlmvaysLA0fPlx+fn7y8PBQ165ddfLkyTKuHgAAAOVBuQi3iYmJeuedd9SgQQOb9ldffVUzZszQnDlzlJiYqMDAQLVt21YXLlyw9omJidGyZcuUkJCgrVu3Kj09XdHR0crJySnrwwAAAICd2f3nd9PT0/Wf//xH7777rs3vHRuGoVmzZmncuHHq0aOHJGnRokUKCAjQBx98oMGDBys1NVXz58/XkiVL1KZNG0nS0qVLFRISonXr1ql9+/Z2OSYAAHBzK+tfk7T3rxkePXpUYWFh+vHHH9WoUSO71nK97H7ldujQoercubM1nOY5cuSIkpOT1a5dO2ubi4uLmjdvrm3btkmSdu3apUuXLtn0CQ4OVnh4uLVPQbKyspSWlmYzAQAA3Ez69u0ri8Wip59+Ot+yIUOGyGKxqG/fvmVfmJ3ZNdwmJCTohx9+UFxcXL5lycnJkqSAgACb9oCAAOuy5ORkOTs7q3LlyoX2KUhcXJy8vb2tU0hIyPUeCgAAQJkLCQlRQkKCMjMzrW0XL17Uhx9+qGrVqtmxMvuxW7g9ceKE/vvf/2rp0qVydXUttJ/FYrGZNwwjX9uVrtZn7NixSk1NtU4nTpy4tuIBAADKgcaNG6tatWr67LPPrG2fffaZQkJCdOedd1rbVq1apfvuu0+VKlWSr6+voqOjdfjw4SK3vX//fnXq1EkVK1ZUQECAevfurdOnT9+wYyktdgu3u3btUkpKipo0aSJHR0c5Ojpq8+bNeuONN+To6Gi9YnvlFdiUlBTrssDAQGVnZ+vcuXOF9imIi4uLvLy8bCYAAICbUb9+/bRw4ULr/IIFC9S/f3+bPhkZGRoxYoQSExO1fv16VahQQd27d1dubm6B20xKSlLz5s3VqFEj7dy5U6tWrdJff/2lnj173tBjKQ12C7etW7fW3r17tXv3buvUtGlT/ec//9Hu3bt1++23KzAwUGvXrrWuk52drc2bNysqKkqS1KRJEzk5Odn0SUpK0r59+6x9AAAAzKx3797aunWrjh49qmPHjunbb7/VE088YdPnoYceUo8ePVSrVi01atRI8+fP1969e7V///4Ctzl37lw1btxYU6ZMUd26dXXnnXdqwYIF2rhxo3777beyOKwSs9vdEjw9PRUeHm7T5uHhIV9fX2t7TEyMpkyZolq1aqlWrVqaMmWK3N3d1atXL0mSt7e3BgwYoJEjR8rX11c+Pj4aNWqUIiIi8n1BDQAAwIz8/PzUuXNnLVq0SIZhqHPnzvLz87Ppc/jwYb344ovasWOHTp8+bb1ie/z48Xx5TPrnE/aNGzeqYsWK+ZYdPnxYtWvXvjEHUwrsfiuwoowePVqZmZkaMmSIzp07p2bNmmnNmjXy9PS09pk5c6YcHR3Vs2dPZWZmqnXr1oqPj5eDg4MdKwcAACg7/fv317BhwyRJb775Zr7lXbp0UUhIiN59910FBwcrNzdX4eHhys7OLnB7ubm56tKli6ZOnZpvWVBQUOkWX8rKVbjdtGmTzbzFYlFsbKxiY2MLXcfV1VWzZ8/W7Nmzb2xxAAAA5VSHDh2sQfXK+/yfOXNGBw4c0Ntvv637779fkrR169Yit9e4cWN9+umnql69uhwdy1VcvCq73+cWAAAA18fBwUEHDhzQgQMH8n16XblyZfn6+uqdd97RoUOHtGHDBo0YMaLI7Q0dOlRnz57V448/ru+//16///671qxZo/79+5f7X4G9uaI4AABAGbD3L4aVRGF3f6pQoYISEhL07LPPKjw8XHXq1NEbb7yhFi1aFLqt4OBgffvttxozZozat2+vrKwshYaGqkOHDqpQoXxfGyXcAgAA3ITi4+OLXL58+XLrv9u0aZPvzgiGYVj/Xb16dZt5SapVq5bN/XNvFuU7egMAAADXgHALAAAA0yDcAgAAwDQItwAAADANwi0AALjlXfllKthHaTwPhFsAAHDLyrsnbGG/1IWy9ffff0uSnJycSrwNbgUGAABuWY6OjnJ3d9epU6fk5ORU7u/halaGYejvv/9WSkqKKlWqlO+HKK4F4RYAANyyLBaLgoKCdOTIER07dsze5dzyKlWqpMDAwOvaBuEWAADc0pydnVWrVi2GJtiZk5PTdV2xzUO4BQAAt7wKFSrI1dXV3mWgFDCwBAAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZh13A7d+5cNWjQQF5eXvLy8lJkZKS+/vpr6/K+ffvKYrHYTPfcc4/NNrKysjR8+HD5+fnJw8NDXbt21cmTJ8v6UAAAAFAO2DXcVq1aVa+88op27typnTt3qlWrVnrwwQf1888/W/t06NBBSUlJ1mnlypU224iJidGyZcuUkJCgrVu3Kj09XdHR0crJySnrwwEAAICdOdpz5126dLGZf/nllzV37lzt2LFDd9xxhyTJxcVFgYGBBa6fmpqq+fPna8mSJWrTpo0kaenSpQoJCdG6devUvn37G3sAAAAAKFfKzZjbnJwcJSQkKCMjQ5GRkdb2TZs2yd/fX7Vr19bAgQOVkpJiXbZr1y5dunRJ7dq1s7YFBwcrPDxc27ZtK3RfWVlZSktLs5kAAABw87N7uN27d68qVqwoFxcXPf3001q2bJnq168vSerYsaPef/99bdiwQdOnT1diYqJatWqlrKwsSVJycrKcnZ1VuXJlm20GBAQoOTm50H3GxcXJ29vbOoWEhNy4AwQAAECZseuwBEmqU6eOdu/erfPnz+vTTz9Vnz59tHnzZtWvX1+PPvqotV94eLiaNm2q0NBQffXVV+rRo0eh2zQMQxaLpdDlY8eO1YgRI6zzaWlpBFwAAAATsHu4dXZ2Vs2aNSVJTZs2VWJiol5//XW9/fbb+foGBQUpNDRUBw8elCQFBgYqOztb586ds7l6m5KSoqioqEL36eLiIhcXl1I+EgAAANib3YclXMkwDOuwgyudOXNGJ06cUFBQkCSpSZMmcnJy0tq1a619kpKStG/fviLDLQAAAMzJrlduX3jhBXXs2FEhISG6cOGCEhIStGnTJq1atUrp6emKjY3VQw89pKCgIB09elQvvPCC/Pz81L17d0mSt7e3BgwYoJEjR8rX11c+Pj4aNWqUIiIirHdPAAAAwK3DruH2r7/+Uu/evZWUlCRvb281aNBAq1atUtu2bZWZmam9e/dq8eLFOn/+vIKCgtSyZUt99NFH8vT0tG5j5syZcnR0VM+ePZWZmanWrVsrPj5eDg4OdjwyAAAA2IPFMAzD3kXYW1pamry9vZWamiovLy97lwOT+21aX3uXgDJUe1S8vUsAAFMobl4rd2NuAQAAgJIi3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA07Bpu586dqwYNGsjLy0teXl6KjIzU119/bV1uGIZiY2MVHBwsNzc3tWjRQj///LPNNrKysjR8+HD5+fnJw8NDXbt21cmTJ8v6UAAAAFAO2DXcVq1aVa+88op27typnTt3qlWrVnrwwQetAfbVV1/VjBkzNGfOHCUmJiowMFBt27bVhQsXrNuIiYnRsmXLlJCQoK1btyo9PV3R0dHKycmx12EBAADATiyGYRj2LuLffHx89Nprr6l///4KDg5WTEyMxowZI+mfq7QBAQGaOnWqBg8erNTUVFWpUkVLlizRo48+Kkn6888/FRISopUrV6p9+/bF2mdaWpq8vb2VmpoqLy+vG3ZsgCT9Nq2vvUtAGao9Kt7eJQCAKRQ3r5WbMbc5OTlKSEhQRkaGIiMjdeTIESUnJ6tdu3bWPi4uLmrevLm2bdsmSdq1a5cuXbpk0yc4OFjh4eHWPgXJyspSWlqazQQAAICbn6O9C9i7d68iIyN18eJFVaxYUcuWLVP9+vWt4TQgIMCmf0BAgI4dOyZJSk5OlrOzsypXrpyvT3JycqH7jIuL08SJE0v5SAAAuDXxidStpbx/ImX3K7d16tTR7t27tWPHDj3zzDPq06eP9u/fb11usVhs+huGka/tSlfrM3bsWKWmplqnEydOXN9BAAAAoFywe7h1dnZWzZo11bRpU8XFxalhw4Z6/fXXFRgYKEn5rsCmpKRYr+YGBgYqOztb586dK7RPQVxcXKx3aMibAAAAcPOze7i9kmEYysrKUlhYmAIDA7V27VrrsuzsbG3evFlRUVGSpCZNmsjJycmmT1JSkvbt22ftAwAAgFuHXcfcvvDCC+rYsaNCQkJ04cIFJSQkaNOmTVq1apUsFotiYmI0ZcoU1apVS7Vq1dKUKVPk7u6uXr16SZK8vb01YMAAjRw5Ur6+vvLx8dGoUaMUERGhNm3a2PPQAAAAYAd2Dbd//fWXevfuraSkJHl7e6tBgwZatWqV2rZtK0kaPXq0MjMzNWTIEJ07d07NmjXTmjVr5Onpad3GzJkz5ejoqJ49eyozM1OtW7dWfHy8HBwc7HVYAAAAsJNyd59be+A+tyhLfKv41lLev1UMlAbe124t9npfu+nucwsAAABcL8ItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATMOu4TYuLk533XWXPD095e/vr27duunXX3+16dO3b19ZLBab6Z577rHpk5WVpeHDh8vPz08eHh7q2rWrTp48WZaHAgAAgHLAruF28+bNGjp0qHbs2KG1a9fq8uXLateunTIyMmz6dejQQUlJSdZp5cqVNstjYmK0bNkyJSQkaOvWrUpPT1d0dLRycnLK8nAAAABgZ4723PmqVats5hcuXCh/f3/t2rVLDzzwgLXdxcVFgYGBBW4jNTVV8+fP15IlS9SmTRtJ0tKlSxUSEqJ169apffv2N+4AAAAAUK6UqzG3qampkiQfHx+b9k2bNsnf31+1a9fWwIEDlZKSYl22a9cuXbp0Se3atbO2BQcHKzw8XNu2bStwP1lZWUpLS7OZAAAAcPMrN+HWMAyNGDFC9913n8LDw63tHTt21Pvvv68NGzZo+vTpSkxMVKtWrZSVlSVJSk5OlrOzsypXrmyzvYCAACUnJxe4r7i4OHl7e1unkJCQG3dgAAAAKDN2HZbwb8OGDdNPP/2krVu32rQ/+uij1n+Hh4eradOmCg0N1VdffaUePXoUuj3DMGSxWApcNnbsWI0YMcI6n5aWRsAFAAAwgXJx5Xb48OH64osvtHHjRlWtWrXIvkFBQQoNDdXBgwclSYGBgcrOzta5c+ds+qWkpCggIKDAbbi4uMjLy8tmAgAAwM3PruHWMAwNGzZMn332mTZs2KCwsLCrrnPmzBmdOHFCQUFBkqQmTZrIyclJa9eutfZJSkrSvn37FBUVdcNqBwAAQPlj12EJQ4cO1QcffKDPP/9cnp6e1jGy3t7ecnNzU3p6umJjY/XQQw8pKChIR48e1QsvvCA/Pz91797d2nfAgAEaOXKkfH195ePjo1GjRikiIsJ69wQAAADcGuwabufOnStJatGihU37woUL1bdvXzk4OGjv3r1avHixzp8/r6CgILVs2VIfffSRPD09rf1nzpwpR0dH9ezZU5mZmWrdurXi4+Pl4OBQlocDAAAAO7NruDUMo8jlbm5uWr169VW34+rqqtmzZ2v27NmlVRoAAABuQuXiC2UAAABAaSDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAAwDQItwAAADANwi0AAABMo0ThtlWrVjp//ny+9rS0NLVq1ep6awIAAABKpEThdtOmTcrOzs7XfvHiRW3ZsuW6iwIAAABKwvFaOv/000/Wf+/fv1/JycnW+ZycHK1atUq33XZb6VUHAAAAXINrCreNGjWSxWKRxWIpcPiBm5ubZs+eXWrFAQAAANfimsLtkSNHZBiGbr/9dn3//feqUqWKdZmzs7P8/f3l4OBQ6kUCAAAAxXFN4TY0NFSSlJube0OKAQAAAK7HNYXbf/vtt9+0adMmpaSk5Au748ePv+7CAAAAgGtVonD77rvv6plnnpGfn58CAwNlsVisyywWC+EWAG5xvcZvsncJKEOxXvauAPg/JQq3kydP1ssvv6wxY8aUdj0AAABAiZXoPrfnzp3TI488Utq1AAAAANelROH2kUce0Zo1a0q7FgAAAOC6lGhYQs2aNfXiiy9qx44dioiIkJOTk83yZ599tlSKAwAAAK5FicLtO++8o4oVK2rz5s3avHmzzTKLxUK4BQAAgF2UKNweOXKktOsAAAAArluJxtwCAAAA5VGJrtz279+/yOULFiwoUTEAAADA9ShRuD137pzN/KVLl7Rv3z6dP39erVq1KpXCAAAAgGtVonC7bNmyfG25ubkaMmSIbr/99usuCgAAACiJUhtzW6FCBT333HOaOXNmaW0SAAAAuCal+oWyw4cP6/Lly6W5SQAAAKDYSjQsYcSIETbzhmEoKSlJX331lfr06VMqhQEAAADXqkTh9scff7SZr1ChgqpUqaLp06df9U4KAAAAwI1SonC7cePG0q4DAAAAuG4lCrd5Tp06pV9//VUWi0W1a9dWlSpVSqsuAAAA4JqV6AtlGRkZ6t+/v4KCgvTAAw/o/vvvV3BwsAYMGKC///67tGsEAAAAiqVE4XbEiBHavHmzvvzyS50/f17nz5/X559/rs2bN2vkyJGlXSMAAABQLCUalvDpp5/qk08+UYsWLaxtnTp1kpubm3r27Km5c+eWVn0AAABAsZXoyu3ff/+tgICAfO3+/v4MSwAAAIDdlCjcRkZGasKECbp48aK1LTMzUxMnTlRkZGSpFQcAAABcixINS5g1a5Y6duyoqlWrqmHDhrJYLNq9e7dcXFy0Zs2a0q4RAAAAKJYShduIiAgdPHhQS5cu1S+//CLDMPTYY4/pP//5j9zc3Eq7RgAAAKBYSjQsIS4uTh9++KEGDhyo6dOna8aMGXrqqaf04YcfaurUqde0nbvuukuenp7y9/dXt27d9Ouvv9r0MQxDsbGxCg4Olpubm1q0aKGff/7Zpk9WVpaGDx8uPz8/eXh4qGvXrjp58mRJDg0AAAA3sRKF27ffflt169bN137HHXdo3rx5xd7O5s2bNXToUO3YsUNr167V5cuX1a5dO2VkZFj7vPrqq5oxY4bmzJmjxMREBQYGqm3btrpw4YK1T0xMjJYtW6aEhARt3bpV6enpio6OVk5OTkkODwAAADepEg1LSE5OVlBQUL72KlWqKCkpqdjbWbVqlc38woUL5e/vr127dumBBx6QYRiaNWuWxo0bpx49ekiSFi1apICAAH3wwQcaPHiwUlNTNX/+fC1ZskRt2rSRJC1dulQhISFat26d2rdvX5JDBAAAwE2oRFduQ0JC9O233+Zr//bbbxUcHFziYlJTUyVJPj4+kqQjR44oOTlZ7dq1s/ZxcXFR8+bNtW3bNknSrl27dOnSJZs+wcHBCg8Pt/a5UlZWltLS0mwmAAAA3PxKdOX2qaeeUkxMjC5duqRWrVpJktavX6/Ro0eX+BfKDMPQiBEjdN999yk8PFzSP1eIJeW7p25AQICOHTtm7ePs7KzKlSvn65O3/pXi4uI0ceLEEtUJAACA8qtE4Xb06NE6e/ashgwZouzsbEmSq6urxowZo7Fjx5aokGHDhumnn37S1q1b8y2zWCw284Zh5Gu7UlF9xo4dqxEjRljn09LSFBISUoKqAQAAUJ6UKNxaLBZNnTpVL774og4cOCA3NzfVqlVLLi4uJSpi+PDh+uKLL/TNN9+oatWq1vbAwEBJ+cf4pqSkWK/mBgYGKjs7W+fOnbO5epuSkqKoqKgC9+fi4lLiWgEAAFB+lWjMbZ6KFSvqrrvuUnh4eInComEYGjZsmD777DNt2LBBYWFhNsvDwsIUGBiotWvXWtuys7O1efNma3Bt0qSJnJycbPokJSVp3759hYZbAAAAmFOJrtyWlqFDh+qDDz7Q559/Lk9PT+sYWW9vb7m5uclisSgmJkZTpkxRrVq1VKtWLU2ZMkXu7u7q1auXte+AAQM0cuRI+fr6ysfHR6NGjVJERIT17gkAAAC4Ndg13M6dO1eS1KJFC5v2hQsXqm/fvpL+Gd+bmZmpIUOG6Ny5c2rWrJnWrFkjT09Pa/+ZM2fK0dFRPXv2VGZmplq3bq34+Hg5ODiU1aEAAACgHLBruDUM46p9LBaLYmNjFRsbW2gfV1dXzZ49W7Nnzy7F6gAAAHCzua4xtwAAAEB5QrgFAACAaRBuAQAAYBqEWwAAAJgG4RYAAACmQbgFAACAaRBuAQAAYBqEWwAAAJgG4RYAAACmQbgFAACAaRBuAQAAYBqEWwAAAJgG4RYAAACmQbgFAACAaRBuAQAAYBqEWwAAAJgG4RYAAACmQbgFAACAaRBuAQAAYBqEWwAAAJgG4RYAAACmQbgFAACAaRBuAQAAYBqEWwAAAJgG4RYAAACmQbgFAACAaRBuAQAAYBqEWwAAAJgG4RYAAACmQbgFAACAaRBuAQAAYBqEWwAAAJgG4RYAAACmQbgFAACAaRBuAQAAYBqEWwAAAJgG4RYAAACmQbgFAACAaRBuAQAAYBqEWwAAAJgG4RYAAACmQbgFAACAadg13H7zzTfq0qWLgoODZbFYtHz5cpvlffv2lcVisZnuuecemz5ZWVkaPny4/Pz85OHhoa5du+rkyZNleBQAAAAoL+wabjMyMtSwYUPNmTOn0D4dOnRQUlKSdVq5cqXN8piYGC1btkwJCQnaunWr0tPTFR0drZycnBtdPgAAAMoZR3vuvGPHjurYsWORfVxcXBQYGFjgstTUVM2fP19LlixRmzZtJElLly5VSEiI1q1bp/bt25d6zQAAACi/yv2Y202bNsnf31+1a9fWwIEDlZKSYl22a9cuXbp0Se3atbO2BQcHKzw8XNu2bSt0m1lZWUpLS7OZAAAAcPMr1+G2Y8eOev/997VhwwZNnz5diYmJatWqlbKysiRJycnJcnZ2VuXKlW3WCwgIUHJycqHbjYuLk7e3t3UKCQm5occBAACAsmHXYQlX8+ijj1r/HR4erqZNmyo0NFRfffWVevToUeh6hmHIYrEUunzs2LEaMWKEdT4tLY2ACwAAYALl+srtlYKCghQaGqqDBw9KkgIDA5Wdna1z587Z9EtJSVFAQECh23FxcZGXl5fNBAAAgJvfTRVuz5w5oxMnTigoKEiS1KRJEzk5OWnt2rXWPklJSdq3b5+ioqLsVSYAAADsxK7DEtLT03Xo0CHr/JEjR7R79275+PjIx8dHsbGxeuihhxQUFKSjR4/qhRdekJ+fn7p37y5J8vb21oABAzRy5Ej5+vrKx8dHo0aNUkREhPXuCQAAALh12DXc7ty5Uy1btrTO542D7dOnj+bOnau9e/dq8eLFOn/+vIKCgtSyZUt99NFH8vT0tK4zc+ZMOTo6qmfPnsrMzFTr1q0VHx8vBweHMj8eAAAA2Jddw22LFi1kGEahy1evXn3Vbbi6umr27NmaPXt2aZYGAACAm9BNNeYWAAAAKArhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZh13D7zTffqEuXLgoODpbFYtHy5cttlhuGodjYWAUHB8vNzU0tWrTQzz//bNMnKytLw4cPl5+fnzw8PNS1a1edPHmyDI8CAAAA5YVdw21GRoYaNmyoOXPmFLj81Vdf1YwZMzRnzhwlJiYqMDBQbdu21YULF6x9YmJitGzZMiUkJGjr1q1KT09XdHS0cnJyyuowAAAAUE442nPnHTt2VMeOHQtcZhiGZs2apXHjxqlHjx6SpEWLFikgIEAffPCBBg8erNTUVM2fP19LlixRmzZtJElLly5VSEiI1q1bp/bt25fZsQAAAMD+yu2Y2yNHjig5OVnt2rWztrm4uKh58+batm2bJGnXrl26dOmSTZ/g4GCFh4db+xQkKytLaWlpNhMAAABufuU23CYnJ0uSAgICbNoDAgKsy5KTk+Xs7KzKlSsX2qcgcXFx8vb2tk4hISGlXD0AAADsodyG2zwWi8Vm3jCMfG1XulqfsWPHKjU11TqdOHGiVGoFAACAfZXbcBsYGChJ+a7ApqSkWK/mBgYGKjs7W+fOnSu0T0FcXFzk5eVlMwEAAODmV27DbVhYmAIDA7V27VprW3Z2tjZv3qyoqChJUpMmTeTk5GTTJykpSfv27bP2AQAAwK3DrndLSE9P16FDh6zzR44c0e7du+Xj46Nq1aopJiZGU6ZMUa1atVSrVi1NmTJF7u7u6tWrlyTJ29tbAwYM0MiRI+Xr6ysfHx+NGjVKERER1rsnAAAA4NZh13C7c+dOtWzZ0jo/YsQISVKfPn0UHx+v0aNHKzMzU0OGDNG5c+fUrFkzrVmzRp6entZ1Zs6cKUdHR/Xs2VOZmZlq3bq14uPj5eDgUObHAwAAAPuyGIZh2LsIe0tLS5O3t7dSU1MZf4sb7rdpfe1dAspQ7VHx9i7BLnqN32TvElCGYr3i7V0CypC93teKm9fK7ZhbAAAA4FoRbgEAAGAahFsAAACYBuEWAAAApkG4BQAAgGkQbgEAAGAahFsAAACYBuEWAAAApmHXXyjDP7jZ+a0llt8JAQDghuHKLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTKNfhNjY2VhaLxWYKDAy0LjcMQ7GxsQoODpabm5tatGihn3/+2Y4VAwAAwJ7KdbiVpDvuuENJSUnWae/evdZlr776qmbMmKE5c+YoMTFRgYGBatu2rS5cuGDHigEAAGAvjvYu4GocHR1trtbmMQxDs2bN0rhx49SjRw9J0qJFixQQEKAPPvhAgwcPLnSbWVlZysrKss6npaWVfuEAAAAoc+X+yu3BgwcVHByssLAwPfbYY/r9998lSUeOHFFycrLatWtn7evi4qLmzZtr27ZtRW4zLi5O3t7e1ikkJOSGHgMAAADKRrkOt82aNdPixYu1evVqvfvuu0pOTlZUVJTOnDmj5ORkSVJAQIDNOgEBAdZlhRk7dqxSU1Ot04kTJ27YMQAAAKDslOthCR07drT+OyIiQpGRkapRo4YWLVqke+65R5JksVhs1jEMI1/blVxcXOTi4lL6BQMAAMCuyvWV2yt5eHgoIiJCBw8etI7DvfIqbUpKSr6ruQAAALg13FThNisrSwcOHFBQUJDCwsIUGBiotWvXWpdnZ2dr8+bNioqKsmOVAAAAsJdyPSxh1KhR6tKli6pVq6aUlBRNnjxZaWlp6tOnjywWi2JiYjRlyhTVqlVLtWrV0pQpU+Tu7q5evXrZu3QAAADYQbkOtydPntTjjz+u06dPq0qVKrrnnnu0Y8cOhYaGSpJGjx6tzMxMDRkyROfOnVOzZs20Zs0aeXp62rlyAAAA2EO5DrcJCQlFLrdYLIqNjVVsbGzZFAQAAIBy7aYacwsAAAAUhXALAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0zBNuH3rrbcUFhYmV1dXNWnSRFu2bLF3SQAAAChjpgi3H330kWJiYjRu3Dj9+OOPuv/++9WxY0cdP37c3qUBAACgDJki3M6YMUMDBgzQU089pXr16mnWrFkKCQnR3Llz7V0aAAAAypCjvQu4XtnZ2dq1a5eef/55m/Z27dpp27ZtBa6TlZWlrKws63xqaqokKS0t7cYVWoRLWRl22S/sI/1itr1LQBmy1/uKvfG+dmvhfe3WYq/3tbz9GoZRZL+bPtyePn1aOTk5CggIsGkPCAhQcnJygevExcVp4sSJ+dpDQkJuSI3Av31i7wJQtl780N4VADcc72u3GDu/r124cEHe3t6FLr/pw20ei8ViM28YRr62PGPHjtWIESOs87m5uTp79qx8fX0LXQcoDWlpaQoJCdGJEyfk5eVl73IA4LrxvoayYhiGLly4oODg4CL73fTh1s/PTw4ODvmu0qakpOS7mpvHxcVFLi4uNm2VKlW6USUC+Xh5efFHAICp8L6GslDUFds8N/0XypydndWkSROtXbvWpn3t2rWKioqyU1UAAACwh5v+yq0kjRgxQr1791bTpk0VGRmpd955R8ePH9fTTz9t79IAAABQhkwRbh999FGdOXNGkyZNUlJSksLDw7Vy5UqFhobauzTAhouLiyZMmJBvWAwA3Kx4X0N5YzGudj8FAAAA4CZx04+5BQAAAPIQbgEAAGAahFsAAACYBuEWAAAApkG4BcrIW2+9pbCwMLm6uqpJkybasmWLvUsCgBL75ptv1KVLFwUHB8tisWj58uX2LgmQRLgFysRHH32kmJgYjRs3Tj/++KPuv/9+dezYUcePH7d3aQBQIhkZGWrYsKHmzJlj71IAG9wKDCgDzZo1U+PGjTV37lxrW7169dStWzfFxcXZsTIAuH4Wi0XLli1Tt27d7F0KwJVb4EbLzs7Wrl271K5dO5v2du3aadu2bXaqCgAAcyLcAjfY6dOnlZOTo4CAAJv2gIAAJScn26kqAADMiXALlBGLxWIzbxhGvjYAAHB9CLfADebn5ycHB4d8V2lTUlLyXc0FAADXh3AL3GDOzs5q0qSJ1q5da9O+du1aRUVF2akqAADMydHeBQC3ghEjRqh3795q2rSpIiMj9c477+j48eN6+umn7V0aAJRIenq6Dh06ZJ0/cuSIdu/eLR8fH1WrVs2OleFWx63AgDLy1ltv6dVXX1VSUpLCw8M1c+ZMPfDAA/YuCwBKZNOmTWrZsmW+9j59+ig+Pr7sCwL+f4RbAAAAmAZjbgEAAGAahFsAAACYBuEWAAAApkG4BQAAgGkQbgEAAGAahFsAAACYBuEWAAAApkG4BQAAgGkQbgEAAGAahFsAKCdatGihmJgYe5dhVd7qAYDiINwCgIlkZ2fbuwQAsCvCLQCUA3379tXmzZv1+uuvy2KxyGKx6PDhwxowYIDCwsLk5uamOnXq6PXXX8+3Xrdu3RQXF6fg4GDVrl1bkrRt2zY1atRIrq6uatq0qZYvXy6LxaLdu3db192/f786deqkihUrKiAgQL1799bp06cLrefo0aNl9XAAQIk52rsAAID0+uuv67ffflN4eLgmTZokSapcubKqVq2qjz/+WH5+ftq2bZsGDRqkoKAg9ezZ07ru+vXr5eXlpbVr18owDF24cEFdunRRp06d9MEHH+jYsWP5hhckJSWpefPmGjhwoGbMmKHMzEyNGTNGPXv21IYNGwqsp0qVKmX2eABASRFuAaAc8Pb2lrOzs9zd3RUYGGhtnzhxovXfYWFh2rZtmz7++GObcOvh4aH33ntPzs7OkqR58+bJYrHo3Xfflaurq+rXr68//vhDAwcOtK4zd+5cNW7cWFOmTLG2LViwQCEhIfrtt99Uu3btAusBgPKOcAsA5di8efP03nvv6dixY8rMzFR2drYaNWpk0yciIsIabCXp119/VYMGDeTq6mptu/vuu23W2bVrlzZu3KiKFSvm2+fhw4etwxsA4GZDuAWAcurjjz/Wc889p+nTpysyMlKenp567bXX9N1339n08/DwsJk3DEMWiyVf27/l5uaqS5cumjp1ar79BgUFldIRAEDZI9wCQDnh7OysnJwc6/yWLVsUFRWlIUOGWNsOHz581e3UrVtX77//vrKysuTi4iJJ2rlzp02fxo0b69NPP1X16tXl6Fjwn4Ir6wGAmwF3SwCAcqJ69er67rvvdPToUZ0+fVo1a9bUzp07tXr1av3222968cUXlZiYeNXt9OrVS7m5uRo0aJAOHDig1atXa9q0aZJkvaI7dOhQnT17Vo8//ri+//57/f7771qzZo369+9vDbRX1pObm3vjDh4ASgnhFgDKiVGjRsnBwUH169dXlSpV1KFDB/Xo0UOPPvqomjVrpjNnzthcxS2Ml5eXvvzyS+3evVuNGjXSuHHjNH78eEmyjsMNDg7Wt99+q5ycHLVv317h4eH673//K29vb1WoUKHAeo4fP37jDh4ASonFuHIgFgDAdN5//33169dPqampcnNzs3c5AHDDMOYWAExo8eLFuv3223Xbbbdpz5491nvYEmwBmB3hFgBMKDk5WePHj1dycrKCgoL0yCOP6OWXX7Z3WQBwwzEsAQAAAKbBF8oAAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBp/H/uX31iQQSdCAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_palette('muted')\n",
    "target_mapping = {'1': 'Heart Disease', '0': 'No Heart Disease'}\n",
    "dataset['target'] = dataset['target'].replace(target_mapping)\n",
    "gender_mapping = {'1': 'Male', '0': 'Female'}\n",
    "dataset['sex'] = dataset['sex'].replace(gender_mapping)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(data=dataset, x='target', hue='sex')\n",
    "plt.title('Heart Disease vs No Heart Disease for males and females')\n",
    "plt.legend(['Female','Male'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de9e75ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 32)                448       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,130\n",
      "Trainable params: 1,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iug\\AppData\\Local\\Temp\\ipykernel_12548\\1937753037.py:11: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  X = np.array(dataset.drop(['target'], 1)) #feature columns from excel file, we have dropped target as it represents the output\n",
      "C:\\Users\\iug\\anaconda3\\envs\\tr\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 4ms/step - loss: 3.9636 - accuracy: 0.5356 - val_loss: 1.1826 - val_accuracy: 0.6602\n",
      "Epoch 2/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.3092 - accuracy: 0.5802 - val_loss: 0.8658 - val_accuracy: 0.6602\n",
      "Epoch 3/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0449 - accuracy: 0.5609 - val_loss: 0.7854 - val_accuracy: 0.6893\n",
      "Epoch 4/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.8925 - accuracy: 0.6068 - val_loss: 0.7388 - val_accuracy: 0.7184\n",
      "Epoch 5/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.8498 - accuracy: 0.5971 - val_loss: 0.7603 - val_accuracy: 0.7670\n",
      "Epoch 6/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.8040 - accuracy: 0.6188 - val_loss: 0.7087 - val_accuracy: 0.7087\n",
      "Epoch 7/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.7405 - accuracy: 0.6828 - val_loss: 0.7581 - val_accuracy: 0.6796\n",
      "Epoch 8/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.7547 - accuracy: 0.6779 - val_loss: 0.6478 - val_accuracy: 0.7767\n",
      "Epoch 9/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.7112 - accuracy: 0.7081 - val_loss: 0.6315 - val_accuracy: 0.8447\n",
      "Epoch 10/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.7467 - val_loss: 0.6364 - val_accuracy: 0.7379\n",
      "Epoch 11/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.7020 - accuracy: 0.7177 - val_loss: 0.6399 - val_accuracy: 0.7476\n",
      "Epoch 12/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.7346 - accuracy: 0.6900 - val_loss: 0.8461 - val_accuracy: 0.6019\n",
      "Epoch 13/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6948 - accuracy: 0.7250 - val_loss: 0.5886 - val_accuracy: 0.8544\n",
      "Epoch 14/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.7358 - val_loss: 0.5856 - val_accuracy: 0.8350\n",
      "Epoch 15/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.7293 - accuracy: 0.6924 - val_loss: 0.6011 - val_accuracy: 0.8447\n",
      "Epoch 16/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6510 - accuracy: 0.7684 - val_loss: 0.6271 - val_accuracy: 0.7670\n",
      "Epoch 17/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.7084 - accuracy: 0.7069 - val_loss: 0.5927 - val_accuracy: 0.8252\n",
      "Epoch 18/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6778 - accuracy: 0.7250 - val_loss: 0.6386 - val_accuracy: 0.7282\n",
      "Epoch 19/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6699 - accuracy: 0.7551 - val_loss: 0.5796 - val_accuracy: 0.8350\n",
      "Epoch 20/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6665 - accuracy: 0.7298 - val_loss: 0.8629 - val_accuracy: 0.5631\n",
      "Epoch 21/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6491 - accuracy: 0.7648 - val_loss: 0.5656 - val_accuracy: 0.8544\n",
      "Epoch 22/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6453 - accuracy: 0.7672 - val_loss: 0.5648 - val_accuracy: 0.8350\n",
      "Epoch 23/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6847 - accuracy: 0.7262 - val_loss: 0.5487 - val_accuracy: 0.8544\n",
      "Epoch 24/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6235 - accuracy: 0.7624 - val_loss: 0.5403 - val_accuracy: 0.8641\n",
      "Epoch 25/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6488 - accuracy: 0.7624 - val_loss: 0.5343 - val_accuracy: 0.8738\n",
      "Epoch 26/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.7045 - val_loss: 0.5363 - val_accuracy: 0.8738\n",
      "Epoch 27/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6523 - accuracy: 0.7539 - val_loss: 0.5246 - val_accuracy: 0.8641\n",
      "Epoch 28/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6622 - accuracy: 0.7382 - val_loss: 0.8599 - val_accuracy: 0.5340\n",
      "Epoch 29/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6600 - accuracy: 0.7443 - val_loss: 0.5488 - val_accuracy: 0.8738\n",
      "Epoch 30/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6280 - accuracy: 0.7780 - val_loss: 0.5411 - val_accuracy: 0.8350\n",
      "Epoch 31/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6484 - accuracy: 0.7624 - val_loss: 0.5216 - val_accuracy: 0.8835\n",
      "Epoch 32/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6463 - accuracy: 0.7575 - val_loss: 0.5561 - val_accuracy: 0.8252\n",
      "Epoch 33/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6510 - accuracy: 0.7539 - val_loss: 0.5507 - val_accuracy: 0.8447\n",
      "Epoch 34/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6388 - accuracy: 0.7636 - val_loss: 0.6630 - val_accuracy: 0.7476\n",
      "Epoch 35/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6778 - accuracy: 0.7358 - val_loss: 0.6898 - val_accuracy: 0.6990\n",
      "Epoch 36/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6514 - accuracy: 0.7551 - val_loss: 0.5977 - val_accuracy: 0.7670\n",
      "Epoch 37/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.7201 - val_loss: 0.6032 - val_accuracy: 0.7864\n",
      "Epoch 38/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6292 - accuracy: 0.7612 - val_loss: 0.6475 - val_accuracy: 0.7476\n",
      "Epoch 39/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6588 - accuracy: 0.7419 - val_loss: 0.5591 - val_accuracy: 0.8252\n",
      "Epoch 40/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6496 - accuracy: 0.7479 - val_loss: 0.6105 - val_accuracy: 0.7476\n",
      "Epoch 41/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6177 - accuracy: 0.7829 - val_loss: 0.5188 - val_accuracy: 0.8738\n",
      "Epoch 42/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6332 - accuracy: 0.7660 - val_loss: 0.5125 - val_accuracy: 0.8932\n",
      "Epoch 43/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5865 - accuracy: 0.7889 - val_loss: 0.4957 - val_accuracy: 0.8544\n",
      "Epoch 44/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6357 - accuracy: 0.7467 - val_loss: 0.7708 - val_accuracy: 0.6117\n",
      "Epoch 45/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6737 - accuracy: 0.7274 - val_loss: 0.6102 - val_accuracy: 0.7670\n",
      "Epoch 46/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6019 - accuracy: 0.7853 - val_loss: 0.5407 - val_accuracy: 0.8252\n",
      "Epoch 47/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6063 - accuracy: 0.7768 - val_loss: 0.6279 - val_accuracy: 0.7476\n",
      "Epoch 48/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.7515 - val_loss: 0.5001 - val_accuracy: 0.8835\n",
      "Epoch 49/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5957 - accuracy: 0.7817 - val_loss: 0.5846 - val_accuracy: 0.7767\n",
      "Epoch 50/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.7104 - accuracy: 0.7008 - val_loss: 0.5325 - val_accuracy: 0.8641\n",
      "Epoch 51/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6014 - accuracy: 0.7853 - val_loss: 0.4972 - val_accuracy: 0.8544\n",
      "Epoch 52/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6176 - accuracy: 0.7636 - val_loss: 0.6793 - val_accuracy: 0.7184\n",
      "Epoch 53/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6242 - accuracy: 0.7539 - val_loss: 0.5097 - val_accuracy: 0.8544\n",
      "Epoch 54/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.7113 - accuracy: 0.6888 - val_loss: 0.6234 - val_accuracy: 0.7476\n",
      "Epoch 55/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6339 - accuracy: 0.7527 - val_loss: 0.5184 - val_accuracy: 0.8350\n",
      "Epoch 56/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6258 - accuracy: 0.7551 - val_loss: 0.5351 - val_accuracy: 0.8252\n",
      "Epoch 57/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.7491 - val_loss: 0.5070 - val_accuracy: 0.8641\n",
      "Epoch 58/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6410 - accuracy: 0.7551 - val_loss: 0.6126 - val_accuracy: 0.7670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6022 - accuracy: 0.7780 - val_loss: 0.5072 - val_accuracy: 0.8738\n",
      "Epoch 60/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6313 - accuracy: 0.7419 - val_loss: 0.5222 - val_accuracy: 0.8447\n",
      "Epoch 61/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6218 - accuracy: 0.7491 - val_loss: 0.6997 - val_accuracy: 0.6602\n",
      "Epoch 62/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6756 - accuracy: 0.7201 - val_loss: 0.6262 - val_accuracy: 0.7476\n",
      "Epoch 63/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5902 - accuracy: 0.7780 - val_loss: 0.6396 - val_accuracy: 0.7379\n",
      "Epoch 64/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6170 - accuracy: 0.7563 - val_loss: 0.4945 - val_accuracy: 0.8544\n",
      "Epoch 65/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5882 - accuracy: 0.7877 - val_loss: 0.5037 - val_accuracy: 0.8350\n",
      "Epoch 66/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6506 - accuracy: 0.7105 - val_loss: 0.7349 - val_accuracy: 0.6505\n",
      "Epoch 67/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6212 - accuracy: 0.7587 - val_loss: 0.5066 - val_accuracy: 0.8447\n",
      "Epoch 68/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6108 - accuracy: 0.7575 - val_loss: 0.5089 - val_accuracy: 0.8447\n",
      "Epoch 69/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.7877 - val_loss: 0.4771 - val_accuracy: 0.8544\n",
      "Epoch 70/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6134 - accuracy: 0.7600 - val_loss: 0.4873 - val_accuracy: 0.8544\n",
      "Epoch 71/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5876 - accuracy: 0.7949 - val_loss: 0.4849 - val_accuracy: 0.8350\n",
      "Epoch 72/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5795 - accuracy: 0.7865 - val_loss: 0.5000 - val_accuracy: 0.8447\n",
      "Epoch 73/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5911 - accuracy: 0.7768 - val_loss: 0.4849 - val_accuracy: 0.8544\n",
      "Epoch 74/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5886 - accuracy: 0.7817 - val_loss: 0.5614 - val_accuracy: 0.7670\n",
      "Epoch 75/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5586 - accuracy: 0.7925 - val_loss: 0.5468 - val_accuracy: 0.7767\n",
      "Epoch 76/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5615 - accuracy: 0.7865 - val_loss: 0.5468 - val_accuracy: 0.8058\n",
      "Epoch 77/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6243 - accuracy: 0.7527 - val_loss: 0.4776 - val_accuracy: 0.8641\n",
      "Epoch 78/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5915 - accuracy: 0.7587 - val_loss: 0.5237 - val_accuracy: 0.8252\n",
      "Epoch 79/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5857 - accuracy: 0.7648 - val_loss: 0.4757 - val_accuracy: 0.8641\n",
      "Epoch 80/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5539 - accuracy: 0.7877 - val_loss: 0.6380 - val_accuracy: 0.7379\n",
      "Epoch 81/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5512 - accuracy: 0.7998 - val_loss: 0.5012 - val_accuracy: 0.8252\n",
      "Epoch 82/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6334 - accuracy: 0.7370 - val_loss: 0.4785 - val_accuracy: 0.8641\n",
      "Epoch 83/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5821 - accuracy: 0.7744 - val_loss: 0.8532 - val_accuracy: 0.5340\n",
      "Epoch 84/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6252 - accuracy: 0.7358 - val_loss: 0.4745 - val_accuracy: 0.8738\n",
      "Epoch 85/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5884 - accuracy: 0.7768 - val_loss: 0.4887 - val_accuracy: 0.8447\n",
      "Epoch 86/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5964 - accuracy: 0.7648 - val_loss: 0.5841 - val_accuracy: 0.7670\n",
      "Epoch 87/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5541 - accuracy: 0.8022 - val_loss: 0.5151 - val_accuracy: 0.8155\n",
      "Epoch 88/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5566 - accuracy: 0.7901 - val_loss: 0.4998 - val_accuracy: 0.8252\n",
      "Epoch 89/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6351 - accuracy: 0.7491 - val_loss: 0.7515 - val_accuracy: 0.6408\n",
      "Epoch 90/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5611 - accuracy: 0.8070 - val_loss: 0.4558 - val_accuracy: 0.8932\n",
      "Epoch 91/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5506 - accuracy: 0.7937 - val_loss: 0.4730 - val_accuracy: 0.8544\n",
      "Epoch 92/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5913 - accuracy: 0.7684 - val_loss: 0.5180 - val_accuracy: 0.8155\n",
      "Epoch 93/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5777 - accuracy: 0.7865 - val_loss: 0.5200 - val_accuracy: 0.7961\n",
      "Epoch 94/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6052 - accuracy: 0.7660 - val_loss: 0.6992 - val_accuracy: 0.6990\n",
      "Epoch 95/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5788 - accuracy: 0.7720 - val_loss: 0.5938 - val_accuracy: 0.7670\n",
      "Epoch 96/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5984 - accuracy: 0.7527 - val_loss: 0.5866 - val_accuracy: 0.7476\n",
      "Epoch 97/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6116 - accuracy: 0.7575 - val_loss: 0.5008 - val_accuracy: 0.8350\n",
      "Epoch 98/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5775 - accuracy: 0.7817 - val_loss: 0.5088 - val_accuracy: 0.8155\n",
      "Epoch 99/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5661 - accuracy: 0.7961 - val_loss: 0.4667 - val_accuracy: 0.8641\n",
      "Epoch 100/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5768 - accuracy: 0.7853 - val_loss: 0.4815 - val_accuracy: 0.8835\n",
      "Epoch 101/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5747 - accuracy: 0.7865 - val_loss: 0.4608 - val_accuracy: 0.8641\n",
      "Epoch 102/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5652 - accuracy: 0.7949 - val_loss: 0.5221 - val_accuracy: 0.8058\n",
      "Epoch 103/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5595 - accuracy: 0.7877 - val_loss: 0.5788 - val_accuracy: 0.7670\n",
      "Epoch 104/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5777 - accuracy: 0.7913 - val_loss: 0.5734 - val_accuracy: 0.7670\n",
      "Epoch 105/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5835 - accuracy: 0.7684 - val_loss: 0.4591 - val_accuracy: 0.8641\n",
      "Epoch 106/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5518 - accuracy: 0.7841 - val_loss: 0.5384 - val_accuracy: 0.7670\n",
      "Epoch 107/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5948 - accuracy: 0.7612 - val_loss: 0.5744 - val_accuracy: 0.7476\n",
      "Epoch 108/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6180 - accuracy: 0.7515 - val_loss: 0.5087 - val_accuracy: 0.8350\n",
      "Epoch 109/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5796 - accuracy: 0.7853 - val_loss: 0.5117 - val_accuracy: 0.8058\n",
      "Epoch 110/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5492 - accuracy: 0.8022 - val_loss: 0.4917 - val_accuracy: 0.8641\n",
      "Epoch 111/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5691 - accuracy: 0.7877 - val_loss: 0.4667 - val_accuracy: 0.8544\n",
      "Epoch 112/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6400 - accuracy: 0.7394 - val_loss: 0.5066 - val_accuracy: 0.8544\n",
      "Epoch 113/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5383 - accuracy: 0.8046 - val_loss: 0.4624 - val_accuracy: 0.8738\n",
      "Epoch 114/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5574 - accuracy: 0.7817 - val_loss: 0.5185 - val_accuracy: 0.7961\n",
      "Epoch 115/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6116 - accuracy: 0.7503 - val_loss: 0.6357 - val_accuracy: 0.7184\n",
      "Epoch 116/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5734 - accuracy: 0.7793 - val_loss: 0.5098 - val_accuracy: 0.7961\n",
      "Epoch 117/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5630 - accuracy: 0.7877 - val_loss: 0.4584 - val_accuracy: 0.8641\n",
      "Epoch 118/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6116 - accuracy: 0.7624 - val_loss: 0.5218 - val_accuracy: 0.7767\n",
      "Epoch 119/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5540 - accuracy: 0.7877 - val_loss: 0.4644 - val_accuracy: 0.8641\n",
      "Epoch 120/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.7877 - val_loss: 0.4586 - val_accuracy: 0.8544\n",
      "Epoch 121/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5477 - accuracy: 0.7937 - val_loss: 0.4504 - val_accuracy: 0.8641\n",
      "Epoch 122/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5352 - accuracy: 0.8106 - val_loss: 0.5346 - val_accuracy: 0.7670\n",
      "Epoch 123/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5603 - accuracy: 0.7817 - val_loss: 0.4593 - val_accuracy: 0.8738\n",
      "Epoch 124/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6020 - accuracy: 0.7563 - val_loss: 0.4713 - val_accuracy: 0.8544\n",
      "Epoch 125/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5646 - accuracy: 0.7780 - val_loss: 0.5592 - val_accuracy: 0.7670\n",
      "Epoch 126/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.7973 - val_loss: 0.4963 - val_accuracy: 0.7961\n",
      "Epoch 127/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6008 - accuracy: 0.7612 - val_loss: 0.5108 - val_accuracy: 0.8447\n",
      "Epoch 128/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5614 - accuracy: 0.7696 - val_loss: 0.7255 - val_accuracy: 0.6505\n",
      "Epoch 129/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5804 - accuracy: 0.7648 - val_loss: 0.5500 - val_accuracy: 0.7573\n",
      "Epoch 130/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6148 - accuracy: 0.7262 - val_loss: 0.4890 - val_accuracy: 0.8641\n",
      "Epoch 131/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5577 - accuracy: 0.7744 - val_loss: 0.5100 - val_accuracy: 0.7670\n",
      "Epoch 132/900\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.5363 - accuracy: 0.8058 - val_loss: 0.5208 - val_accuracy: 0.7670\n",
      "Epoch 133/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5683 - accuracy: 0.7780 - val_loss: 0.4521 - val_accuracy: 0.8738\n",
      "Epoch 134/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5868 - accuracy: 0.7503 - val_loss: 0.4699 - val_accuracy: 0.8447\n",
      "Epoch 135/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5448 - accuracy: 0.7829 - val_loss: 0.5115 - val_accuracy: 0.7670\n",
      "Epoch 136/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5458 - accuracy: 0.8070 - val_loss: 0.4553 - val_accuracy: 0.8544\n",
      "Epoch 137/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5742 - accuracy: 0.7612 - val_loss: 0.6753 - val_accuracy: 0.6796\n",
      "Epoch 138/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5575 - accuracy: 0.7913 - val_loss: 0.4505 - val_accuracy: 0.8544\n",
      "Epoch 139/900\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5568 - accuracy: 0.7889 - val_loss: 0.4546 - val_accuracy: 0.8641\n",
      "Epoch 140/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5447 - accuracy: 0.8022 - val_loss: 0.4672 - val_accuracy: 0.8252\n",
      "Epoch 141/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5774 - accuracy: 0.7600 - val_loss: 0.5212 - val_accuracy: 0.7670\n",
      "Epoch 142/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5454 - accuracy: 0.7998 - val_loss: 0.4704 - val_accuracy: 0.8252\n",
      "Epoch 143/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6230 - accuracy: 0.7455 - val_loss: 0.5795 - val_accuracy: 0.7282\n",
      "Epoch 144/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7949 - val_loss: 0.4760 - val_accuracy: 0.8252\n",
      "Epoch 145/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5890 - accuracy: 0.7636 - val_loss: 0.4696 - val_accuracy: 0.8738\n",
      "Epoch 146/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5891 - accuracy: 0.7612 - val_loss: 0.5190 - val_accuracy: 0.7670\n",
      "Epoch 147/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5529 - accuracy: 0.7853 - val_loss: 0.6394 - val_accuracy: 0.6990\n",
      "Epoch 148/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5419 - accuracy: 0.7998 - val_loss: 0.4636 - val_accuracy: 0.8738\n",
      "Epoch 149/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5283 - accuracy: 0.7925 - val_loss: 0.4587 - val_accuracy: 0.8544\n",
      "Epoch 150/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5295 - accuracy: 0.8179 - val_loss: 0.4472 - val_accuracy: 0.8447\n",
      "Epoch 151/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.7901 - val_loss: 0.4567 - val_accuracy: 0.8447\n",
      "Epoch 152/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.7038 - accuracy: 0.6852 - val_loss: 0.5474 - val_accuracy: 0.7670\n",
      "Epoch 153/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5458 - accuracy: 0.7756 - val_loss: 0.4792 - val_accuracy: 0.8738\n",
      "Epoch 154/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.8094 - val_loss: 0.4551 - val_accuracy: 0.8544\n",
      "Epoch 155/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5507 - accuracy: 0.7853 - val_loss: 0.4703 - val_accuracy: 0.8447\n",
      "Epoch 156/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5844 - accuracy: 0.7756 - val_loss: 0.4997 - val_accuracy: 0.7864\n",
      "Epoch 157/900\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5644 - accuracy: 0.7925 - val_loss: 0.4743 - val_accuracy: 0.8350\n",
      "Epoch 158/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5400 - accuracy: 0.7756 - val_loss: 0.4768 - val_accuracy: 0.8544\n",
      "Epoch 159/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5656 - accuracy: 0.7732 - val_loss: 0.4826 - val_accuracy: 0.8252\n",
      "Epoch 160/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5740 - accuracy: 0.7744 - val_loss: 0.5122 - val_accuracy: 0.7670\n",
      "Epoch 161/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5872 - accuracy: 0.7708 - val_loss: 0.5338 - val_accuracy: 0.7670\n",
      "Epoch 162/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5478 - accuracy: 0.7841 - val_loss: 0.5963 - val_accuracy: 0.7184\n",
      "Epoch 163/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5294 - accuracy: 0.8010 - val_loss: 0.5381 - val_accuracy: 0.7476\n",
      "Epoch 164/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.8010 - val_loss: 0.4522 - val_accuracy: 0.8641\n",
      "Epoch 165/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5556 - accuracy: 0.7817 - val_loss: 0.4449 - val_accuracy: 0.8738\n",
      "Epoch 166/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5545 - accuracy: 0.7841 - val_loss: 0.4676 - val_accuracy: 0.8350\n",
      "Epoch 167/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.7901 - val_loss: 0.4794 - val_accuracy: 0.8058\n",
      "Epoch 168/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.7865 - val_loss: 0.4336 - val_accuracy: 0.8544\n",
      "Epoch 169/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6046 - accuracy: 0.7491 - val_loss: 0.5093 - val_accuracy: 0.7767\n",
      "Epoch 170/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5416 - accuracy: 0.8058 - val_loss: 0.4610 - val_accuracy: 0.8544\n",
      "Epoch 171/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.8058 - val_loss: 0.5049 - val_accuracy: 0.8252\n",
      "Epoch 172/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5720 - accuracy: 0.7732 - val_loss: 0.5158 - val_accuracy: 0.7573\n",
      "Epoch 173/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5686 - accuracy: 0.7817 - val_loss: 0.4930 - val_accuracy: 0.7864\n",
      "Epoch 174/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5713 - accuracy: 0.7732 - val_loss: 0.4963 - val_accuracy: 0.7961\n",
      "Epoch 175/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.7877 - val_loss: 0.4611 - val_accuracy: 0.8738\n",
      "Epoch 176/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5341 - accuracy: 0.8010 - val_loss: 0.4609 - val_accuracy: 0.8252\n",
      "Epoch 177/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5752 - accuracy: 0.7648 - val_loss: 0.4646 - val_accuracy: 0.8641\n",
      "Epoch 178/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5522 - accuracy: 0.7756 - val_loss: 0.4973 - val_accuracy: 0.7670\n",
      "Epoch 179/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5488 - accuracy: 0.7865 - val_loss: 0.4758 - val_accuracy: 0.8447\n",
      "Epoch 180/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.7913 - val_loss: 0.4750 - val_accuracy: 0.8155\n",
      "Epoch 181/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.8130 - val_loss: 0.5286 - val_accuracy: 0.7476\n",
      "Epoch 182/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5614 - accuracy: 0.7973 - val_loss: 0.4579 - val_accuracy: 0.8641\n",
      "Epoch 183/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.8022 - val_loss: 0.4581 - val_accuracy: 0.8155\n",
      "Epoch 184/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.8179 - val_loss: 0.5930 - val_accuracy: 0.7379\n",
      "Epoch 185/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5429 - accuracy: 0.7793 - val_loss: 0.4915 - val_accuracy: 0.8058\n",
      "Epoch 186/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5544 - accuracy: 0.7913 - val_loss: 0.5371 - val_accuracy: 0.7961\n",
      "Epoch 187/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5953 - accuracy: 0.7636 - val_loss: 0.5021 - val_accuracy: 0.7670\n",
      "Epoch 188/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.8130 - val_loss: 0.5156 - val_accuracy: 0.7670\n",
      "Epoch 189/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5458 - accuracy: 0.7817 - val_loss: 0.4494 - val_accuracy: 0.8835\n",
      "Epoch 190/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5316 - accuracy: 0.7961 - val_loss: 0.4814 - val_accuracy: 0.8641\n",
      "Epoch 191/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5449 - accuracy: 0.7817 - val_loss: 0.4652 - val_accuracy: 0.8738\n",
      "Epoch 192/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.7901 - val_loss: 0.4471 - val_accuracy: 0.8738\n",
      "Epoch 193/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.8118 - val_loss: 0.4528 - val_accuracy: 0.8738\n",
      "Epoch 194/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5787 - accuracy: 0.7841 - val_loss: 0.4914 - val_accuracy: 0.7767\n",
      "Epoch 195/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5221 - accuracy: 0.8142 - val_loss: 0.4736 - val_accuracy: 0.8058\n",
      "Epoch 196/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5382 - accuracy: 0.7925 - val_loss: 0.7609 - val_accuracy: 0.6505\n",
      "Epoch 197/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5928 - accuracy: 0.7527 - val_loss: 0.5295 - val_accuracy: 0.7670\n",
      "Epoch 198/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.7865 - val_loss: 0.4561 - val_accuracy: 0.8738\n",
      "Epoch 199/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5252 - accuracy: 0.7841 - val_loss: 0.4491 - val_accuracy: 0.8641\n",
      "Epoch 200/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.7829 - val_loss: 0.4314 - val_accuracy: 0.8738\n",
      "Epoch 201/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5333 - accuracy: 0.8022 - val_loss: 0.4536 - val_accuracy: 0.8835\n",
      "Epoch 202/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.8094 - val_loss: 0.4729 - val_accuracy: 0.8641\n",
      "Epoch 203/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5587 - accuracy: 0.7768 - val_loss: 0.4546 - val_accuracy: 0.8641\n",
      "Epoch 204/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5413 - accuracy: 0.7877 - val_loss: 0.4529 - val_accuracy: 0.8835\n",
      "Epoch 205/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.8142 - val_loss: 0.4923 - val_accuracy: 0.7670\n",
      "Epoch 206/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7913 - val_loss: 0.5353 - val_accuracy: 0.7476\n",
      "Epoch 207/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5520 - accuracy: 0.7865 - val_loss: 0.4439 - val_accuracy: 0.8641\n",
      "Epoch 208/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.7889 - val_loss: 0.5807 - val_accuracy: 0.7670\n",
      "Epoch 209/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5641 - accuracy: 0.7587 - val_loss: 0.4615 - val_accuracy: 0.8738\n",
      "Epoch 210/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.8010 - val_loss: 0.4741 - val_accuracy: 0.7961\n",
      "Epoch 211/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.8166 - val_loss: 0.4846 - val_accuracy: 0.8058\n",
      "Epoch 212/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.8130 - val_loss: 0.4266 - val_accuracy: 0.8932\n",
      "Epoch 213/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.8154 - val_loss: 0.4350 - val_accuracy: 0.8350\n",
      "Epoch 214/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.8275 - val_loss: 0.4230 - val_accuracy: 0.9029\n",
      "Epoch 215/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5537 - accuracy: 0.7865 - val_loss: 0.4461 - val_accuracy: 0.8155\n",
      "Epoch 216/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.8094 - val_loss: 0.4261 - val_accuracy: 0.8738\n",
      "Epoch 217/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7901 - val_loss: 0.4386 - val_accuracy: 0.8835\n",
      "Epoch 218/900\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5153 - accuracy: 0.7986 - val_loss: 0.5218 - val_accuracy: 0.7864\n",
      "Epoch 219/900\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5693 - accuracy: 0.7648 - val_loss: 0.5048 - val_accuracy: 0.7670\n",
      "Epoch 220/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5848 - accuracy: 0.7660 - val_loss: 0.5256 - val_accuracy: 0.7670\n",
      "Epoch 221/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.7973 - val_loss: 0.4619 - val_accuracy: 0.8641\n",
      "Epoch 222/900\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.7925 - val_loss: 0.4843 - val_accuracy: 0.7864\n",
      "Epoch 223/900\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5223 - accuracy: 0.8070 - val_loss: 0.4866 - val_accuracy: 0.8252\n",
      "Epoch 224/900\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5387 - accuracy: 0.7793 - val_loss: 0.4451 - val_accuracy: 0.8544\n",
      "Epoch 225/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5585 - accuracy: 0.7708 - val_loss: 0.4798 - val_accuracy: 0.7767\n",
      "Epoch 226/900\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5627 - accuracy: 0.7732 - val_loss: 0.4571 - val_accuracy: 0.8738\n",
      "Epoch 227/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.8046 - val_loss: 0.4492 - val_accuracy: 0.8641\n",
      "Epoch 228/900\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.4962 - accuracy: 0.8179 - val_loss: 0.4670 - val_accuracy: 0.8447\n",
      "Epoch 229/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.8082 - val_loss: 0.4220 - val_accuracy: 0.8835\n",
      "Epoch 230/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5354 - accuracy: 0.7949 - val_loss: 0.5495 - val_accuracy: 0.7670\n",
      "Epoch 231/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.8082 - val_loss: 0.6054 - val_accuracy: 0.7379\n",
      "Epoch 232/900\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5149 - accuracy: 0.8239 - val_loss: 0.5214 - val_accuracy: 0.7670\n",
      "Epoch 233/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.8154 - val_loss: 0.4875 - val_accuracy: 0.7864\n",
      "Epoch 234/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.8166 - val_loss: 0.4245 - val_accuracy: 0.8932\n",
      "Epoch 235/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.8070 - val_loss: 0.4288 - val_accuracy: 0.8738\n",
      "Epoch 236/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5832 - accuracy: 0.7624 - val_loss: 0.4460 - val_accuracy: 0.9029\n",
      "Epoch 237/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5332 - accuracy: 0.7865 - val_loss: 0.4429 - val_accuracy: 0.9029\n",
      "Epoch 238/900\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.8022 - val_loss: 0.4322 - val_accuracy: 0.8641\n",
      "Epoch 239/900\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5238 - accuracy: 0.7986 - val_loss: 0.5033 - val_accuracy: 0.7670\n",
      "Epoch 240/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.7877 - val_loss: 0.4429 - val_accuracy: 0.8738\n",
      "Epoch 241/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5332 - accuracy: 0.7937 - val_loss: 0.4458 - val_accuracy: 0.8252\n",
      "Epoch 242/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5410 - accuracy: 0.8070 - val_loss: 0.4852 - val_accuracy: 0.8544\n",
      "Epoch 243/900\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5215 - accuracy: 0.8022 - val_loss: 0.4771 - val_accuracy: 0.7864\n",
      "Epoch 244/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.8227 - val_loss: 0.4242 - val_accuracy: 0.8835\n",
      "Epoch 245/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.8142 - val_loss: 0.4943 - val_accuracy: 0.7864\n",
      "Epoch 246/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.7998 - val_loss: 0.4345 - val_accuracy: 0.8641\n",
      "Epoch 247/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.8070 - val_loss: 0.4550 - val_accuracy: 0.8447\n",
      "Epoch 248/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.8010 - val_loss: 0.4521 - val_accuracy: 0.8447\n",
      "Epoch 249/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7986 - val_loss: 0.4616 - val_accuracy: 0.8350\n",
      "Epoch 250/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.7973 - val_loss: 0.6371 - val_accuracy: 0.7282\n",
      "Epoch 251/900\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5823 - accuracy: 0.7684 - val_loss: 0.5251 - val_accuracy: 0.7670\n",
      "Epoch 252/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4996 - accuracy: 0.8142 - val_loss: 0.4331 - val_accuracy: 0.9029\n",
      "Epoch 253/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.8106 - val_loss: 0.5191 - val_accuracy: 0.7767\n",
      "Epoch 254/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.8094 - val_loss: 0.4723 - val_accuracy: 0.8058\n",
      "Epoch 255/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4992 - accuracy: 0.8239 - val_loss: 0.5475 - val_accuracy: 0.7476\n",
      "Epoch 256/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.7805 - val_loss: 0.4779 - val_accuracy: 0.8350\n",
      "Epoch 257/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5907 - accuracy: 0.7382 - val_loss: 0.5174 - val_accuracy: 0.7670\n",
      "Epoch 258/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5469 - accuracy: 0.7937 - val_loss: 0.6897 - val_accuracy: 0.6699\n",
      "Epoch 259/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.8034 - val_loss: 0.4956 - val_accuracy: 0.7670\n",
      "Epoch 260/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7841 - val_loss: 0.4767 - val_accuracy: 0.8641\n",
      "Epoch 261/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.7937 - val_loss: 0.4569 - val_accuracy: 0.8155\n",
      "Epoch 262/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7949 - val_loss: 0.4441 - val_accuracy: 0.8738\n",
      "Epoch 263/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5257 - accuracy: 0.8010 - val_loss: 0.4349 - val_accuracy: 0.9029\n",
      "Epoch 264/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5356 - accuracy: 0.7901 - val_loss: 0.4453 - val_accuracy: 0.8738\n",
      "Epoch 265/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5523 - accuracy: 0.7889 - val_loss: 0.4456 - val_accuracy: 0.8738\n",
      "Epoch 266/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5257 - accuracy: 0.7961 - val_loss: 0.4607 - val_accuracy: 0.8738\n",
      "Epoch 267/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.8034 - val_loss: 0.4353 - val_accuracy: 0.8641\n",
      "Epoch 268/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.8203 - val_loss: 0.4390 - val_accuracy: 0.8641\n",
      "Epoch 269/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5371 - accuracy: 0.7865 - val_loss: 0.4314 - val_accuracy: 0.8544\n",
      "Epoch 270/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5270 - accuracy: 0.7937 - val_loss: 0.4509 - val_accuracy: 0.8350\n",
      "Epoch 271/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.8106 - val_loss: 0.4457 - val_accuracy: 0.8155\n",
      "Epoch 272/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7829 - val_loss: 0.4229 - val_accuracy: 0.9029\n",
      "Epoch 273/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.7853 - val_loss: 0.4792 - val_accuracy: 0.8447\n",
      "Epoch 274/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.8082 - val_loss: 0.4351 - val_accuracy: 0.8252\n",
      "Epoch 275/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5853 - accuracy: 0.7672 - val_loss: 0.4656 - val_accuracy: 0.8447\n",
      "Epoch 276/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5674 - accuracy: 0.7563 - val_loss: 0.6106 - val_accuracy: 0.7573\n",
      "Epoch 277/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 0.7768 - val_loss: 0.5094 - val_accuracy: 0.8058\n",
      "Epoch 278/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.8094 - val_loss: 0.4367 - val_accuracy: 0.8932\n",
      "Epoch 279/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.8179 - val_loss: 0.4599 - val_accuracy: 0.8252\n",
      "Epoch 280/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5699 - accuracy: 0.7660 - val_loss: 0.4436 - val_accuracy: 0.8932\n",
      "Epoch 281/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.8154 - val_loss: 0.4270 - val_accuracy: 0.8835\n",
      "Epoch 282/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5503 - accuracy: 0.7817 - val_loss: 0.4463 - val_accuracy: 0.8641\n",
      "Epoch 283/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5764 - accuracy: 0.7708 - val_loss: 0.4867 - val_accuracy: 0.7864\n",
      "Epoch 284/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.8046 - val_loss: 0.6506 - val_accuracy: 0.6893\n",
      "Epoch 285/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5558 - accuracy: 0.7660 - val_loss: 0.4753 - val_accuracy: 0.7864\n",
      "Epoch 286/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.8082 - val_loss: 0.4441 - val_accuracy: 0.8738\n",
      "Epoch 287/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.8106 - val_loss: 0.4409 - val_accuracy: 0.8738\n",
      "Epoch 288/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.8179 - val_loss: 0.4806 - val_accuracy: 0.7864\n",
      "Epoch 289/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7889 - val_loss: 0.4488 - val_accuracy: 0.8252\n",
      "Epoch 290/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7961 - val_loss: 0.4395 - val_accuracy: 0.8350\n",
      "Epoch 291/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.8010 - val_loss: 0.4378 - val_accuracy: 0.8641\n",
      "Epoch 292/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5400 - accuracy: 0.7913 - val_loss: 0.4738 - val_accuracy: 0.7961\n",
      "Epoch 293/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.8118 - val_loss: 0.4510 - val_accuracy: 0.8252\n",
      "Epoch 294/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5338 - accuracy: 0.8022 - val_loss: 0.4975 - val_accuracy: 0.8447\n",
      "Epoch 295/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5664 - accuracy: 0.7817 - val_loss: 0.5054 - val_accuracy: 0.7670\n",
      "Epoch 296/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.7793 - val_loss: 0.4525 - val_accuracy: 0.8641\n",
      "Epoch 297/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.8118 - val_loss: 0.4911 - val_accuracy: 0.8544\n",
      "Epoch 298/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5901 - accuracy: 0.7696 - val_loss: 0.4611 - val_accuracy: 0.8738\n",
      "Epoch 299/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7913 - val_loss: 0.4657 - val_accuracy: 0.8350\n",
      "Epoch 300/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.8130 - val_loss: 0.4898 - val_accuracy: 0.7864\n",
      "Epoch 301/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5670 - accuracy: 0.7551 - val_loss: 0.5215 - val_accuracy: 0.7670\n",
      "Epoch 302/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.8215 - val_loss: 0.6031 - val_accuracy: 0.7282\n",
      "Epoch 303/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5334 - accuracy: 0.7865 - val_loss: 0.4321 - val_accuracy: 0.8932\n",
      "Epoch 304/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5374 - accuracy: 0.7925 - val_loss: 0.4861 - val_accuracy: 0.7864\n",
      "Epoch 305/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.8106 - val_loss: 0.4291 - val_accuracy: 0.8641\n",
      "Epoch 306/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.8082 - val_loss: 0.4632 - val_accuracy: 0.8155\n",
      "Epoch 307/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5289 - accuracy: 0.7913 - val_loss: 0.4706 - val_accuracy: 0.8058\n",
      "Epoch 308/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.8130 - val_loss: 0.4314 - val_accuracy: 0.8738\n",
      "Epoch 309/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.8335 - val_loss: 0.4748 - val_accuracy: 0.7767\n",
      "Epoch 310/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.8118 - val_loss: 0.4161 - val_accuracy: 0.8835\n",
      "Epoch 311/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.8251 - val_loss: 0.4296 - val_accuracy: 0.8252\n",
      "Epoch 312/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.8251 - val_loss: 0.4379 - val_accuracy: 0.8350\n",
      "Epoch 313/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.8118 - val_loss: 0.4178 - val_accuracy: 0.8641\n",
      "Epoch 314/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7998 - val_loss: 0.4761 - val_accuracy: 0.8252\n",
      "Epoch 315/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.8034 - val_loss: 0.4142 - val_accuracy: 0.9029\n",
      "Epoch 316/900\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.4993 - accuracy: 0.8118 - val_loss: 0.6262 - val_accuracy: 0.7087\n",
      "Epoch 317/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.8082 - val_loss: 0.4161 - val_accuracy: 0.8835\n",
      "Epoch 318/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.8166 - val_loss: 0.4100 - val_accuracy: 0.9029\n",
      "Epoch 319/900\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.8311 - val_loss: 0.4854 - val_accuracy: 0.7767\n",
      "Epoch 320/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.7889 - val_loss: 0.4324 - val_accuracy: 0.8738\n",
      "Epoch 321/900\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5699 - accuracy: 0.7587 - val_loss: 0.9347 - val_accuracy: 0.5534\n",
      "Epoch 322/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.7913 - val_loss: 0.4460 - val_accuracy: 0.8738\n",
      "Epoch 323/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7937 - val_loss: 0.4552 - val_accuracy: 0.8252\n",
      "Epoch 324/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.8203 - val_loss: 0.4214 - val_accuracy: 0.8738\n",
      "Epoch 325/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.8082 - val_loss: 0.4415 - val_accuracy: 0.8155\n",
      "Epoch 326/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.8203 - val_loss: 0.4201 - val_accuracy: 0.8738\n",
      "Epoch 327/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.8154 - val_loss: 0.4104 - val_accuracy: 0.8544\n",
      "Epoch 328/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.8130 - val_loss: 0.6918 - val_accuracy: 0.6893\n",
      "Epoch 329/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5325 - accuracy: 0.7961 - val_loss: 0.4277 - val_accuracy: 0.8350\n",
      "Epoch 330/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.8227 - val_loss: 0.5049 - val_accuracy: 0.7670\n",
      "Epoch 331/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4997 - accuracy: 0.8022 - val_loss: 0.4039 - val_accuracy: 0.9029\n",
      "Epoch 332/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5668 - accuracy: 0.7793 - val_loss: 0.4330 - val_accuracy: 0.8738\n",
      "Epoch 333/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.7817 - val_loss: 0.4479 - val_accuracy: 0.8447\n",
      "Epoch 334/900\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.7973 - val_loss: 0.4628 - val_accuracy: 0.8544\n",
      "Epoch 335/900\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5276 - accuracy: 0.7961 - val_loss: 0.4289 - val_accuracy: 0.9029\n",
      "Epoch 336/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.8142 - val_loss: 0.4507 - val_accuracy: 0.8252\n",
      "Epoch 337/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7937 - val_loss: 0.5216 - val_accuracy: 0.7670\n",
      "Epoch 338/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.8215 - val_loss: 0.4242 - val_accuracy: 0.8641\n",
      "Epoch 339/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5412 - accuracy: 0.7961 - val_loss: 0.5078 - val_accuracy: 0.7670\n",
      "Epoch 340/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7998 - val_loss: 0.4322 - val_accuracy: 0.8350\n",
      "Epoch 341/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5796 - accuracy: 0.7684 - val_loss: 0.4664 - val_accuracy: 0.7961\n",
      "Epoch 342/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7949 - val_loss: 0.4536 - val_accuracy: 0.8155\n",
      "Epoch 343/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.8130 - val_loss: 0.4177 - val_accuracy: 0.9029\n",
      "Epoch 344/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.8046 - val_loss: 0.4264 - val_accuracy: 0.8641\n",
      "Epoch 345/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.8323 - val_loss: 0.4454 - val_accuracy: 0.8155\n",
      "Epoch 346/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.8058 - val_loss: 0.4157 - val_accuracy: 0.9029\n",
      "Epoch 347/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7961 - val_loss: 0.4222 - val_accuracy: 0.8835\n",
      "Epoch 348/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4996 - accuracy: 0.8239 - val_loss: 0.4125 - val_accuracy: 0.8932\n",
      "Epoch 349/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.7973 - val_loss: 0.4188 - val_accuracy: 0.9029\n",
      "Epoch 350/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.8299 - val_loss: 0.4197 - val_accuracy: 0.8932\n",
      "Epoch 351/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5410 - accuracy: 0.7865 - val_loss: 0.5066 - val_accuracy: 0.7767\n",
      "Epoch 352/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5014 - accuracy: 0.8094 - val_loss: 0.4320 - val_accuracy: 0.8544\n",
      "Epoch 353/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.8118 - val_loss: 0.4213 - val_accuracy: 0.8641\n",
      "Epoch 354/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7961 - val_loss: 0.4923 - val_accuracy: 0.8058\n",
      "Epoch 355/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7889 - val_loss: 0.4236 - val_accuracy: 0.8738\n",
      "Epoch 356/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.8082 - val_loss: 0.4137 - val_accuracy: 0.9029\n",
      "Epoch 357/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.7986 - val_loss: 0.4508 - val_accuracy: 0.8738\n",
      "Epoch 358/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5663 - accuracy: 0.7648 - val_loss: 0.4504 - val_accuracy: 0.8252\n",
      "Epoch 359/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.8058 - val_loss: 0.4981 - val_accuracy: 0.7670\n",
      "Epoch 360/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7913 - val_loss: 0.4487 - val_accuracy: 0.8252\n",
      "Epoch 361/900\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.8166 - val_loss: 0.4165 - val_accuracy: 0.8641\n",
      "Epoch 362/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.8010 - val_loss: 0.4126 - val_accuracy: 0.8932\n",
      "Epoch 363/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.8034 - val_loss: 0.4348 - val_accuracy: 0.8544\n",
      "Epoch 364/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.8179 - val_loss: 0.4234 - val_accuracy: 0.8641\n",
      "Epoch 365/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.8058 - val_loss: 0.4223 - val_accuracy: 0.8835\n",
      "Epoch 366/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.8034 - val_loss: 0.4204 - val_accuracy: 0.8738\n",
      "Epoch 367/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5325 - accuracy: 0.7913 - val_loss: 0.4761 - val_accuracy: 0.8058\n",
      "Epoch 368/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.8203 - val_loss: 0.4218 - val_accuracy: 0.8350\n",
      "Epoch 369/900\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.4839 - accuracy: 0.8179 - val_loss: 0.4155 - val_accuracy: 0.8350\n",
      "Epoch 370/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.8046 - val_loss: 0.4549 - val_accuracy: 0.8058\n",
      "Epoch 371/900\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.8106 - val_loss: 0.4507 - val_accuracy: 0.8252\n",
      "Epoch 372/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.8070 - val_loss: 0.4275 - val_accuracy: 0.8738\n",
      "Epoch 373/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5447 - accuracy: 0.7793 - val_loss: 0.4723 - val_accuracy: 0.7767\n",
      "Epoch 374/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.8203 - val_loss: 0.4127 - val_accuracy: 0.9029\n",
      "Epoch 375/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.8142 - val_loss: 0.4246 - val_accuracy: 0.8252\n",
      "Epoch 376/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7973 - val_loss: 0.4323 - val_accuracy: 0.8252\n",
      "Epoch 377/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.7937 - val_loss: 0.5539 - val_accuracy: 0.7573\n",
      "Epoch 378/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.7973 - val_loss: 0.4195 - val_accuracy: 0.8350\n",
      "Epoch 379/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.8070 - val_loss: 0.4100 - val_accuracy: 0.8738\n",
      "Epoch 380/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.8094 - val_loss: 0.4619 - val_accuracy: 0.8447\n",
      "Epoch 381/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.8034 - val_loss: 0.4128 - val_accuracy: 0.8835\n",
      "Epoch 382/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.8130 - val_loss: 0.4306 - val_accuracy: 0.8544\n",
      "Epoch 383/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.8082 - val_loss: 0.4773 - val_accuracy: 0.7864\n",
      "Epoch 384/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.7949 - val_loss: 0.4824 - val_accuracy: 0.7670\n",
      "Epoch 385/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7925 - val_loss: 0.4158 - val_accuracy: 0.9029\n",
      "Epoch 386/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5381 - accuracy: 0.7780 - val_loss: 0.4679 - val_accuracy: 0.7767\n",
      "Epoch 387/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.8142 - val_loss: 0.4626 - val_accuracy: 0.7961\n",
      "Epoch 388/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.8203 - val_loss: 0.4424 - val_accuracy: 0.8252\n",
      "Epoch 389/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.8118 - val_loss: 0.4299 - val_accuracy: 0.8155\n",
      "Epoch 390/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4978 - accuracy: 0.8130 - val_loss: 0.5419 - val_accuracy: 0.7573\n",
      "Epoch 391/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.8299 - val_loss: 0.4008 - val_accuracy: 0.8641\n",
      "Epoch 392/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.8323 - val_loss: 0.4137 - val_accuracy: 0.8738\n",
      "Epoch 393/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.8034 - val_loss: 0.4596 - val_accuracy: 0.7864\n",
      "Epoch 394/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4934 - accuracy: 0.7949 - val_loss: 0.4432 - val_accuracy: 0.8155\n",
      "Epoch 395/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.8118 - val_loss: 0.4202 - val_accuracy: 0.8641\n",
      "Epoch 396/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7841 - val_loss: 0.4514 - val_accuracy: 0.8155\n",
      "Epoch 397/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.8203 - val_loss: 0.4519 - val_accuracy: 0.7961\n",
      "Epoch 398/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.8239 - val_loss: 0.5190 - val_accuracy: 0.7670\n",
      "Epoch 399/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.8215 - val_loss: 0.4096 - val_accuracy: 0.8738\n",
      "Epoch 400/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.8179 - val_loss: 0.5210 - val_accuracy: 0.7670\n",
      "Epoch 401/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6293 - accuracy: 0.7322 - val_loss: 0.4371 - val_accuracy: 0.8544\n",
      "Epoch 402/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.8142 - val_loss: 0.4279 - val_accuracy: 0.8738\n",
      "Epoch 403/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.8034 - val_loss: 0.4640 - val_accuracy: 0.7961\n",
      "Epoch 404/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.8263 - val_loss: 0.4137 - val_accuracy: 0.8544\n",
      "Epoch 405/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.8263 - val_loss: 0.4784 - val_accuracy: 0.7961\n",
      "Epoch 406/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7817 - val_loss: 0.4079 - val_accuracy: 0.8835\n",
      "Epoch 407/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.7986 - val_loss: 0.4056 - val_accuracy: 0.8835\n",
      "Epoch 408/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.8058 - val_loss: 0.4836 - val_accuracy: 0.7670\n",
      "Epoch 409/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7949 - val_loss: 0.4812 - val_accuracy: 0.7670\n",
      "Epoch 410/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.8347 - val_loss: 0.4258 - val_accuracy: 0.8252\n",
      "Epoch 411/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.8203 - val_loss: 0.3995 - val_accuracy: 0.8835\n",
      "Epoch 412/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5283 - accuracy: 0.7865 - val_loss: 0.4118 - val_accuracy: 0.8447\n",
      "Epoch 413/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.8154 - val_loss: 0.4550 - val_accuracy: 0.7961\n",
      "Epoch 414/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.8130 - val_loss: 0.4435 - val_accuracy: 0.8058\n",
      "Epoch 415/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.8227 - val_loss: 0.4108 - val_accuracy: 0.8835\n",
      "Epoch 416/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.8263 - val_loss: 0.4005 - val_accuracy: 0.8932\n",
      "Epoch 417/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.8166 - val_loss: 0.4781 - val_accuracy: 0.7864\n",
      "Epoch 418/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.8046 - val_loss: 0.4055 - val_accuracy: 0.8932\n",
      "Epoch 419/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.8118 - val_loss: 0.5037 - val_accuracy: 0.7670\n",
      "Epoch 420/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7744 - val_loss: 0.4304 - val_accuracy: 0.8544\n",
      "Epoch 421/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.8179 - val_loss: 0.4463 - val_accuracy: 0.8252\n",
      "Epoch 422/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.8299 - val_loss: 0.4065 - val_accuracy: 0.8447\n",
      "Epoch 423/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5016 - accuracy: 0.8106 - val_loss: 0.4508 - val_accuracy: 0.7961\n",
      "Epoch 424/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.8372 - val_loss: 0.4464 - val_accuracy: 0.7961\n",
      "Epoch 425/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.8227 - val_loss: 0.3913 - val_accuracy: 0.8738\n",
      "Epoch 426/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.8154 - val_loss: 0.3958 - val_accuracy: 0.8835\n",
      "Epoch 427/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.8046 - val_loss: 0.4155 - val_accuracy: 0.8350\n",
      "Epoch 428/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.8130 - val_loss: 0.6191 - val_accuracy: 0.7476\n",
      "Epoch 429/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4905 - accuracy: 0.8179 - val_loss: 0.4911 - val_accuracy: 0.7670\n",
      "Epoch 430/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7986 - val_loss: 0.4066 - val_accuracy: 0.9029\n",
      "Epoch 431/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.8022 - val_loss: 0.3951 - val_accuracy: 0.8932\n",
      "Epoch 432/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.8118 - val_loss: 0.5307 - val_accuracy: 0.7573\n",
      "Epoch 433/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7889 - val_loss: 0.4159 - val_accuracy: 0.8350\n",
      "Epoch 434/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.8251 - val_loss: 0.4820 - val_accuracy: 0.7864\n",
      "Epoch 435/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.8034 - val_loss: 0.4487 - val_accuracy: 0.8155\n",
      "Epoch 436/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.8022 - val_loss: 0.4001 - val_accuracy: 0.8932\n",
      "Epoch 437/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.8347 - val_loss: 0.4240 - val_accuracy: 0.8738\n",
      "Epoch 438/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7986 - val_loss: 0.4130 - val_accuracy: 0.8932\n",
      "Epoch 439/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4950 - accuracy: 0.8082 - val_loss: 0.4132 - val_accuracy: 0.8544\n",
      "Epoch 440/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.8227 - val_loss: 0.4720 - val_accuracy: 0.7864\n",
      "Epoch 441/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5260 - accuracy: 0.7998 - val_loss: 0.4429 - val_accuracy: 0.7961\n",
      "Epoch 442/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.8130 - val_loss: 0.4719 - val_accuracy: 0.7961\n",
      "Epoch 443/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4990 - accuracy: 0.8130 - val_loss: 0.6051 - val_accuracy: 0.7379\n",
      "Epoch 444/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4989 - accuracy: 0.8118 - val_loss: 0.4472 - val_accuracy: 0.8350\n",
      "Epoch 445/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.8227 - val_loss: 0.4185 - val_accuracy: 0.8350\n",
      "Epoch 446/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.8154 - val_loss: 0.4019 - val_accuracy: 0.8641\n",
      "Epoch 447/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.8058 - val_loss: 0.4064 - val_accuracy: 0.8835\n",
      "Epoch 448/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.8335 - val_loss: 0.4023 - val_accuracy: 0.8641\n",
      "Epoch 449/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.8106 - val_loss: 0.5402 - val_accuracy: 0.7670\n",
      "Epoch 450/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5308 - accuracy: 0.8010 - val_loss: 0.5096 - val_accuracy: 0.7864\n",
      "Epoch 451/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5220 - accuracy: 0.7925 - val_loss: 0.4138 - val_accuracy: 0.8835\n",
      "Epoch 452/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5002 - accuracy: 0.7973 - val_loss: 0.4112 - val_accuracy: 0.8738\n",
      "Epoch 453/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.7973 - val_loss: 0.5861 - val_accuracy: 0.7379\n",
      "Epoch 454/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5627 - accuracy: 0.7648 - val_loss: 0.4451 - val_accuracy: 0.8738\n",
      "Epoch 455/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7829 - val_loss: 0.4151 - val_accuracy: 0.8835\n",
      "Epoch 456/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4960 - accuracy: 0.8094 - val_loss: 0.4420 - val_accuracy: 0.8252\n",
      "Epoch 457/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5014 - accuracy: 0.7889 - val_loss: 0.4171 - val_accuracy: 0.8641\n",
      "Epoch 458/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.8191 - val_loss: 0.4078 - val_accuracy: 0.8932\n",
      "Epoch 459/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5530 - accuracy: 0.7744 - val_loss: 0.5633 - val_accuracy: 0.7961\n",
      "Epoch 460/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.8227 - val_loss: 0.4454 - val_accuracy: 0.8155\n",
      "Epoch 461/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.8287 - val_loss: 0.4071 - val_accuracy: 0.8932\n",
      "Epoch 462/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4853 - accuracy: 0.8154 - val_loss: 0.4026 - val_accuracy: 0.8932\n",
      "Epoch 463/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.8130 - val_loss: 0.4019 - val_accuracy: 0.8932\n",
      "Epoch 464/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.8106 - val_loss: 0.4133 - val_accuracy: 0.8544\n",
      "Epoch 465/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.8372 - val_loss: 0.3976 - val_accuracy: 0.8932\n",
      "Epoch 466/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.8058 - val_loss: 0.4637 - val_accuracy: 0.7864\n",
      "Epoch 467/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.8118 - val_loss: 0.4076 - val_accuracy: 0.8738\n",
      "Epoch 468/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7973 - val_loss: 0.4393 - val_accuracy: 0.8155\n",
      "Epoch 469/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.8094 - val_loss: 0.4392 - val_accuracy: 0.7961\n",
      "Epoch 470/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.8203 - val_loss: 0.4334 - val_accuracy: 0.8058\n",
      "Epoch 471/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.8106 - val_loss: 0.4802 - val_accuracy: 0.7767\n",
      "Epoch 472/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.8275 - val_loss: 0.5810 - val_accuracy: 0.7476\n",
      "Epoch 473/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.7986 - val_loss: 0.4045 - val_accuracy: 0.8835\n",
      "Epoch 474/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.8010 - val_loss: 0.4164 - val_accuracy: 0.8641\n",
      "Epoch 475/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5605 - accuracy: 0.7817 - val_loss: 0.7846 - val_accuracy: 0.6019\n",
      "Epoch 476/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7877 - val_loss: 0.4171 - val_accuracy: 0.8738\n",
      "Epoch 477/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.8203 - val_loss: 0.4216 - val_accuracy: 0.8447\n",
      "Epoch 478/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7961 - val_loss: 0.4165 - val_accuracy: 0.8738\n",
      "Epoch 479/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.8191 - val_loss: 0.3985 - val_accuracy: 0.8932\n",
      "Epoch 480/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.8239 - val_loss: 0.4860 - val_accuracy: 0.7670\n",
      "Epoch 481/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.8203 - val_loss: 0.3961 - val_accuracy: 0.8738\n",
      "Epoch 482/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.8227 - val_loss: 0.4390 - val_accuracy: 0.8447\n",
      "Epoch 483/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.8166 - val_loss: 0.3884 - val_accuracy: 0.8738\n",
      "Epoch 484/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.8179 - val_loss: 0.3860 - val_accuracy: 0.9029\n",
      "Epoch 485/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.8130 - val_loss: 0.3925 - val_accuracy: 0.8835\n",
      "Epoch 486/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4853 - accuracy: 0.8130 - val_loss: 0.3899 - val_accuracy: 0.9029\n",
      "Epoch 487/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.8227 - val_loss: 0.3923 - val_accuracy: 0.8738\n",
      "Epoch 488/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.8251 - val_loss: 0.3915 - val_accuracy: 0.8738\n",
      "Epoch 489/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.8263 - val_loss: 0.4029 - val_accuracy: 0.8544\n",
      "Epoch 490/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.8335 - val_loss: 0.4390 - val_accuracy: 0.7961\n",
      "Epoch 491/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5220 - accuracy: 0.7901 - val_loss: 0.3992 - val_accuracy: 0.8641\n",
      "Epoch 492/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.8191 - val_loss: 0.3881 - val_accuracy: 0.8738\n",
      "Epoch 493/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.8166 - val_loss: 0.3892 - val_accuracy: 0.8738\n",
      "Epoch 494/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4992 - accuracy: 0.8034 - val_loss: 0.3825 - val_accuracy: 0.8932\n",
      "Epoch 495/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.8287 - val_loss: 0.4423 - val_accuracy: 0.8058\n",
      "Epoch 496/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.8203 - val_loss: 0.4123 - val_accuracy: 0.8350\n",
      "Epoch 497/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.8384 - val_loss: 0.3971 - val_accuracy: 0.8738\n",
      "Epoch 498/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.8323 - val_loss: 0.4401 - val_accuracy: 0.8252\n",
      "Epoch 499/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.8142 - val_loss: 0.4066 - val_accuracy: 0.8641\n",
      "Epoch 500/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.8179 - val_loss: 0.4620 - val_accuracy: 0.7961\n",
      "Epoch 501/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.8034 - val_loss: 0.3973 - val_accuracy: 0.8932\n",
      "Epoch 502/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.8179 - val_loss: 0.4029 - val_accuracy: 0.8738\n",
      "Epoch 503/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.8022 - val_loss: 0.3941 - val_accuracy: 0.8932\n",
      "Epoch 504/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.8251 - val_loss: 0.5923 - val_accuracy: 0.7476\n",
      "Epoch 505/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5531 - accuracy: 0.7793 - val_loss: 0.4422 - val_accuracy: 0.7961\n",
      "Epoch 506/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.8251 - val_loss: 0.5215 - val_accuracy: 0.7573\n",
      "Epoch 507/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.8022 - val_loss: 0.4433 - val_accuracy: 0.7961\n",
      "Epoch 508/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.8130 - val_loss: 0.5293 - val_accuracy: 0.7670\n",
      "Epoch 509/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.8082 - val_loss: 0.5550 - val_accuracy: 0.7573\n",
      "Epoch 510/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.8130 - val_loss: 0.4087 - val_accuracy: 0.8738\n",
      "Epoch 511/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.8130 - val_loss: 0.4760 - val_accuracy: 0.7961\n",
      "Epoch 512/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.8130 - val_loss: 0.4788 - val_accuracy: 0.8155\n",
      "Epoch 513/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.7913 - val_loss: 0.4213 - val_accuracy: 0.8544\n",
      "Epoch 514/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.8372 - val_loss: 0.4890 - val_accuracy: 0.7961\n",
      "Epoch 515/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.8142 - val_loss: 0.4837 - val_accuracy: 0.7670\n",
      "Epoch 516/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.8166 - val_loss: 0.3914 - val_accuracy: 0.8738\n",
      "Epoch 517/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.8179 - val_loss: 0.4009 - val_accuracy: 0.8544\n",
      "Epoch 518/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.8263 - val_loss: 0.3900 - val_accuracy: 0.8641\n",
      "Epoch 519/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.8359 - val_loss: 0.4478 - val_accuracy: 0.8447\n",
      "Epoch 520/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.8227 - val_loss: 0.4077 - val_accuracy: 0.8252\n",
      "Epoch 521/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.8166 - val_loss: 0.3871 - val_accuracy: 0.8932\n",
      "Epoch 522/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.8191 - val_loss: 0.3870 - val_accuracy: 0.8932\n",
      "Epoch 523/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.8118 - val_loss: 0.3801 - val_accuracy: 0.9029\n",
      "Epoch 524/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.8166 - val_loss: 0.4007 - val_accuracy: 0.8738\n",
      "Epoch 525/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.8251 - val_loss: 0.3855 - val_accuracy: 0.8738\n",
      "Epoch 526/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.7986 - val_loss: 0.4303 - val_accuracy: 0.7961\n",
      "Epoch 527/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.8106 - val_loss: 0.3920 - val_accuracy: 0.9029\n",
      "Epoch 528/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.7973 - val_loss: 0.4984 - val_accuracy: 0.7670\n",
      "Epoch 529/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.8070 - val_loss: 0.4987 - val_accuracy: 0.7670\n",
      "Epoch 530/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.8203 - val_loss: 0.4175 - val_accuracy: 0.8252\n",
      "Epoch 531/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.8154 - val_loss: 0.4339 - val_accuracy: 0.7961\n",
      "Epoch 532/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7998 - val_loss: 0.4235 - val_accuracy: 0.8350\n",
      "Epoch 533/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.7973 - val_loss: 0.3980 - val_accuracy: 0.8932\n",
      "Epoch 534/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.8142 - val_loss: 0.4128 - val_accuracy: 0.8252\n",
      "Epoch 535/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.8215 - val_loss: 0.3925 - val_accuracy: 0.8932\n",
      "Epoch 536/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.8299 - val_loss: 0.3816 - val_accuracy: 0.8932\n",
      "Epoch 537/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.8191 - val_loss: 0.3853 - val_accuracy: 0.8932\n",
      "Epoch 538/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.8311 - val_loss: 0.4246 - val_accuracy: 0.8058\n",
      "Epoch 539/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.8082 - val_loss: 0.3806 - val_accuracy: 0.8835\n",
      "Epoch 540/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.8299 - val_loss: 0.4031 - val_accuracy: 0.8738\n",
      "Epoch 541/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.8275 - val_loss: 0.4084 - val_accuracy: 0.8641\n",
      "Epoch 542/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.8408 - val_loss: 0.3929 - val_accuracy: 0.8835\n",
      "Epoch 543/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.8239 - val_loss: 0.3781 - val_accuracy: 0.8932\n",
      "Epoch 544/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.8275 - val_loss: 0.4116 - val_accuracy: 0.8155\n",
      "Epoch 545/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.8359 - val_loss: 0.3760 - val_accuracy: 0.8932\n",
      "Epoch 546/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.8299 - val_loss: 0.3762 - val_accuracy: 0.8835\n",
      "Epoch 547/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.8203 - val_loss: 0.4866 - val_accuracy: 0.7670\n",
      "Epoch 548/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.8034 - val_loss: 0.4155 - val_accuracy: 0.8447\n",
      "Epoch 549/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.8082 - val_loss: 0.4621 - val_accuracy: 0.8155\n",
      "Epoch 550/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.8323 - val_loss: 0.3877 - val_accuracy: 0.8738\n",
      "Epoch 551/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.8118 - val_loss: 0.4176 - val_accuracy: 0.8447\n",
      "Epoch 552/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.8215 - val_loss: 0.4019 - val_accuracy: 0.8350\n",
      "Epoch 553/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.8275 - val_loss: 0.3874 - val_accuracy: 0.8544\n",
      "Epoch 554/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.8347 - val_loss: 0.4265 - val_accuracy: 0.8155\n",
      "Epoch 555/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.7986 - val_loss: 0.3780 - val_accuracy: 0.8641\n",
      "Epoch 556/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.8215 - val_loss: 0.3775 - val_accuracy: 0.8932\n",
      "Epoch 557/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.8179 - val_loss: 0.4312 - val_accuracy: 0.7961\n",
      "Epoch 558/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.8215 - val_loss: 0.3829 - val_accuracy: 0.8738\n",
      "Epoch 559/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.8432 - val_loss: 0.3715 - val_accuracy: 0.8932\n",
      "Epoch 560/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.8251 - val_loss: 0.6149 - val_accuracy: 0.7379\n",
      "Epoch 561/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.8215 - val_loss: 0.4147 - val_accuracy: 0.7961\n",
      "Epoch 562/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.8070 - val_loss: 0.4606 - val_accuracy: 0.7961\n",
      "Epoch 563/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.8275 - val_loss: 0.3807 - val_accuracy: 0.8835\n",
      "Epoch 564/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.8191 - val_loss: 0.4089 - val_accuracy: 0.8835\n",
      "Epoch 565/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.8191 - val_loss: 0.3917 - val_accuracy: 0.8641\n",
      "Epoch 566/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4905 - accuracy: 0.8070 - val_loss: 0.4017 - val_accuracy: 0.8544\n",
      "Epoch 567/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.8130 - val_loss: 0.3864 - val_accuracy: 0.8641\n",
      "Epoch 568/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.8251 - val_loss: 0.4603 - val_accuracy: 0.7864\n",
      "Epoch 569/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.8179 - val_loss: 0.4313 - val_accuracy: 0.8155\n",
      "Epoch 570/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.8179 - val_loss: 0.3962 - val_accuracy: 0.8350\n",
      "Epoch 571/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.8191 - val_loss: 0.4031 - val_accuracy: 0.8544\n",
      "Epoch 572/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.8106 - val_loss: 0.3921 - val_accuracy: 0.8447\n",
      "Epoch 573/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.8215 - val_loss: 0.4617 - val_accuracy: 0.7961\n",
      "Epoch 574/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.8191 - val_loss: 0.4028 - val_accuracy: 0.8350\n",
      "Epoch 575/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.8347 - val_loss: 0.4304 - val_accuracy: 0.7864\n",
      "Epoch 576/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.8070 - val_loss: 0.3894 - val_accuracy: 0.8738\n",
      "Epoch 577/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.8323 - val_loss: 0.3913 - val_accuracy: 0.8447\n",
      "Epoch 578/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.8311 - val_loss: 0.5447 - val_accuracy: 0.7670\n",
      "Epoch 579/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.8251 - val_loss: 0.4076 - val_accuracy: 0.8641\n",
      "Epoch 580/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.8166 - val_loss: 0.3855 - val_accuracy: 0.8641\n",
      "Epoch 581/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.8372 - val_loss: 0.3996 - val_accuracy: 0.8155\n",
      "Epoch 582/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.8130 - val_loss: 0.3742 - val_accuracy: 0.8835\n",
      "Epoch 583/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.8227 - val_loss: 0.3813 - val_accuracy: 0.8544\n",
      "Epoch 584/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.7913 - val_loss: 0.4167 - val_accuracy: 0.8058\n",
      "Epoch 585/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.8046 - val_loss: 0.4208 - val_accuracy: 0.7961\n",
      "Epoch 586/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.8287 - val_loss: 0.4029 - val_accuracy: 0.8544\n",
      "Epoch 587/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.8130 - val_loss: 0.3835 - val_accuracy: 0.8641\n",
      "Epoch 588/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.8227 - val_loss: 0.4007 - val_accuracy: 0.8058\n",
      "Epoch 589/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.8203 - val_loss: 0.4016 - val_accuracy: 0.8447\n",
      "Epoch 590/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.8323 - val_loss: 0.3949 - val_accuracy: 0.8641\n",
      "Epoch 591/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.8444 - val_loss: 0.4335 - val_accuracy: 0.8738\n",
      "Epoch 592/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.8106 - val_loss: 0.4299 - val_accuracy: 0.7961\n",
      "Epoch 593/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.8263 - val_loss: 0.3937 - val_accuracy: 0.8835\n",
      "Epoch 594/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.8046 - val_loss: 0.3846 - val_accuracy: 0.8738\n",
      "Epoch 595/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5013 - accuracy: 0.8022 - val_loss: 0.3903 - val_accuracy: 0.8738\n",
      "Epoch 596/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.8311 - val_loss: 0.4024 - val_accuracy: 0.8058\n",
      "Epoch 597/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.8432 - val_loss: 0.3900 - val_accuracy: 0.8835\n",
      "Epoch 598/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.8227 - val_loss: 0.4054 - val_accuracy: 0.7961\n",
      "Epoch 599/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.8239 - val_loss: 0.4422 - val_accuracy: 0.7864\n",
      "Epoch 600/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.8142 - val_loss: 0.4127 - val_accuracy: 0.8058\n",
      "Epoch 601/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.8299 - val_loss: 0.3774 - val_accuracy: 0.8544\n",
      "Epoch 602/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.8239 - val_loss: 0.4677 - val_accuracy: 0.7961\n",
      "Epoch 603/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.8034 - val_loss: 0.4407 - val_accuracy: 0.7961\n",
      "Epoch 604/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.8299 - val_loss: 0.3822 - val_accuracy: 0.8447\n",
      "Epoch 605/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.8275 - val_loss: 0.3736 - val_accuracy: 0.8544\n",
      "Epoch 606/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.8287 - val_loss: 0.4670 - val_accuracy: 0.8058\n",
      "Epoch 607/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7986 - val_loss: 0.4922 - val_accuracy: 0.7670\n",
      "Epoch 608/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.8227 - val_loss: 0.3769 - val_accuracy: 0.8544\n",
      "Epoch 609/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.8070 - val_loss: 0.4409 - val_accuracy: 0.7961\n",
      "Epoch 610/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.8215 - val_loss: 0.4178 - val_accuracy: 0.8738\n",
      "Epoch 611/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.8034 - val_loss: 0.4316 - val_accuracy: 0.8155\n",
      "Epoch 612/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.8287 - val_loss: 0.3871 - val_accuracy: 0.8738\n",
      "Epoch 613/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.8118 - val_loss: 0.3702 - val_accuracy: 0.9029\n",
      "Epoch 614/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.8239 - val_loss: 0.4200 - val_accuracy: 0.7961\n",
      "Epoch 615/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.8311 - val_loss: 0.3923 - val_accuracy: 0.8252\n",
      "Epoch 616/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.8396 - val_loss: 0.3905 - val_accuracy: 0.8252\n",
      "Epoch 617/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.7986 - val_loss: 0.3865 - val_accuracy: 0.8252\n",
      "Epoch 618/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.8335 - val_loss: 0.3887 - val_accuracy: 0.8835\n",
      "Epoch 619/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.8154 - val_loss: 0.3765 - val_accuracy: 0.8641\n",
      "Epoch 620/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.7925 - val_loss: 0.4690 - val_accuracy: 0.8447\n",
      "Epoch 621/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.7829 - val_loss: 0.3854 - val_accuracy: 0.8544\n",
      "Epoch 622/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.8275 - val_loss: 0.3793 - val_accuracy: 0.8835\n",
      "Epoch 623/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8359 - val_loss: 0.3863 - val_accuracy: 0.8447\n",
      "Epoch 624/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.8335 - val_loss: 0.3611 - val_accuracy: 0.9029\n",
      "Epoch 625/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.8058 - val_loss: 0.3778 - val_accuracy: 0.8738\n",
      "Epoch 626/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.8287 - val_loss: 0.4030 - val_accuracy: 0.8350\n",
      "Epoch 627/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.8058 - val_loss: 0.5272 - val_accuracy: 0.7670\n",
      "Epoch 628/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7998 - val_loss: 0.4302 - val_accuracy: 0.7767\n",
      "Epoch 629/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.8263 - val_loss: 0.4515 - val_accuracy: 0.7961\n",
      "Epoch 630/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.8299 - val_loss: 0.3726 - val_accuracy: 0.8738\n",
      "Epoch 631/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.8323 - val_loss: 0.3685 - val_accuracy: 0.8738\n",
      "Epoch 632/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.8130 - val_loss: 0.3623 - val_accuracy: 0.8932\n",
      "Epoch 633/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.8227 - val_loss: 0.3770 - val_accuracy: 0.8835\n",
      "Epoch 634/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.8191 - val_loss: 0.3679 - val_accuracy: 0.8835\n",
      "Epoch 635/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.8094 - val_loss: 0.3714 - val_accuracy: 0.8835\n",
      "Epoch 636/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7998 - val_loss: 0.3833 - val_accuracy: 0.8447\n",
      "Epoch 637/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.8263 - val_loss: 0.4392 - val_accuracy: 0.7961\n",
      "Epoch 638/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.8142 - val_loss: 0.3678 - val_accuracy: 0.9029\n",
      "Epoch 639/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.8154 - val_loss: 0.4372 - val_accuracy: 0.7961\n",
      "Epoch 640/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.8094 - val_loss: 0.3764 - val_accuracy: 0.8835\n",
      "Epoch 641/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.8275 - val_loss: 0.3853 - val_accuracy: 0.8252\n",
      "Epoch 642/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.8263 - val_loss: 0.4354 - val_accuracy: 0.7961\n",
      "Epoch 643/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.8299 - val_loss: 0.3871 - val_accuracy: 0.8350\n",
      "Epoch 644/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8372 - val_loss: 0.3580 - val_accuracy: 0.8835\n",
      "Epoch 645/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.8227 - val_loss: 0.3744 - val_accuracy: 0.8835\n",
      "Epoch 646/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.8191 - val_loss: 0.3598 - val_accuracy: 0.8835\n",
      "Epoch 647/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.8287 - val_loss: 0.3728 - val_accuracy: 0.8447\n",
      "Epoch 648/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.8263 - val_loss: 0.3590 - val_accuracy: 0.8544\n",
      "Epoch 649/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.8166 - val_loss: 0.4047 - val_accuracy: 0.8350\n",
      "Epoch 650/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.8239 - val_loss: 0.3830 - val_accuracy: 0.8155\n",
      "Epoch 651/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7937 - val_loss: 0.4382 - val_accuracy: 0.8350\n",
      "Epoch 652/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.8275 - val_loss: 0.3868 - val_accuracy: 0.8544\n",
      "Epoch 653/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.8034 - val_loss: 0.4240 - val_accuracy: 0.8641\n",
      "Epoch 654/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.8191 - val_loss: 0.3865 - val_accuracy: 0.8932\n",
      "Epoch 655/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.8347 - val_loss: 0.5279 - val_accuracy: 0.7670\n",
      "Epoch 656/900\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.8191 - val_loss: 0.4359 - val_accuracy: 0.8835\n",
      "Epoch 657/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.8094 - val_loss: 0.3790 - val_accuracy: 0.8641\n",
      "Epoch 658/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.8239 - val_loss: 0.3911 - val_accuracy: 0.8738\n",
      "Epoch 659/900\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.8299 - val_loss: 0.3790 - val_accuracy: 0.8932\n",
      "Epoch 660/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.8396 - val_loss: 0.3979 - val_accuracy: 0.8058\n",
      "Epoch 661/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7768 - val_loss: 0.4014 - val_accuracy: 0.8350\n",
      "Epoch 662/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7961 - val_loss: 0.3779 - val_accuracy: 0.8835\n",
      "Epoch 663/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.8203 - val_loss: 0.3803 - val_accuracy: 0.8835\n",
      "Epoch 664/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.8179 - val_loss: 0.3932 - val_accuracy: 0.8252\n",
      "Epoch 665/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.8118 - val_loss: 0.3877 - val_accuracy: 0.8641\n",
      "Epoch 666/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.8094 - val_loss: 0.3847 - val_accuracy: 0.8641\n",
      "Epoch 667/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.8142 - val_loss: 0.3874 - val_accuracy: 0.8641\n",
      "Epoch 668/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.8215 - val_loss: 0.3789 - val_accuracy: 0.8738\n",
      "Epoch 669/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.8287 - val_loss: 0.4107 - val_accuracy: 0.7961\n",
      "Epoch 670/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.8263 - val_loss: 0.4268 - val_accuracy: 0.7961\n",
      "Epoch 671/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.8203 - val_loss: 0.4076 - val_accuracy: 0.7961\n",
      "Epoch 672/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.8070 - val_loss: 0.3886 - val_accuracy: 0.8252\n",
      "Epoch 673/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.8251 - val_loss: 0.4069 - val_accuracy: 0.8252\n",
      "Epoch 674/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.8275 - val_loss: 0.3904 - val_accuracy: 0.8155\n",
      "Epoch 675/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.8263 - val_loss: 0.5095 - val_accuracy: 0.7961\n",
      "Epoch 676/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.8227 - val_loss: 0.4271 - val_accuracy: 0.7864\n",
      "Epoch 677/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.8251 - val_loss: 0.3885 - val_accuracy: 0.8058\n",
      "Epoch 678/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.8323 - val_loss: 0.4664 - val_accuracy: 0.7864\n",
      "Epoch 679/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.8094 - val_loss: 0.5143 - val_accuracy: 0.7573\n",
      "Epoch 680/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.8130 - val_loss: 0.3955 - val_accuracy: 0.8641\n",
      "Epoch 681/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.8239 - val_loss: 0.3822 - val_accuracy: 0.8447\n",
      "Epoch 682/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7949 - val_loss: 0.3871 - val_accuracy: 0.8738\n",
      "Epoch 683/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.8130 - val_loss: 0.3859 - val_accuracy: 0.8641\n",
      "Epoch 684/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.8323 - val_loss: 0.3824 - val_accuracy: 0.8350\n",
      "Epoch 685/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.8154 - val_loss: 0.4448 - val_accuracy: 0.7864\n",
      "Epoch 686/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.8239 - val_loss: 0.4645 - val_accuracy: 0.7961\n",
      "Epoch 687/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.8191 - val_loss: 0.3916 - val_accuracy: 0.8738\n",
      "Epoch 688/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.8275 - val_loss: 0.3864 - val_accuracy: 0.8544\n",
      "Epoch 689/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.8227 - val_loss: 0.3794 - val_accuracy: 0.8350\n",
      "Epoch 690/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.8179 - val_loss: 0.3970 - val_accuracy: 0.8252\n",
      "Epoch 691/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.8251 - val_loss: 0.3913 - val_accuracy: 0.8058\n",
      "Epoch 692/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.8130 - val_loss: 0.4691 - val_accuracy: 0.7864\n",
      "Epoch 693/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.8070 - val_loss: 0.4271 - val_accuracy: 0.8835\n",
      "Epoch 694/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.8179 - val_loss: 0.4083 - val_accuracy: 0.8544\n",
      "Epoch 695/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.8118 - val_loss: 0.3776 - val_accuracy: 0.8544\n",
      "Epoch 696/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.8251 - val_loss: 0.4058 - val_accuracy: 0.8641\n",
      "Epoch 697/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.8263 - val_loss: 0.4528 - val_accuracy: 0.7961\n",
      "Epoch 698/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.8299 - val_loss: 0.3908 - val_accuracy: 0.8058\n",
      "Epoch 699/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.8094 - val_loss: 0.3863 - val_accuracy: 0.8350\n",
      "Epoch 700/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.8239 - val_loss: 0.4380 - val_accuracy: 0.8447\n",
      "Epoch 701/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.8191 - val_loss: 0.3788 - val_accuracy: 0.8350\n",
      "Epoch 702/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.8227 - val_loss: 0.3740 - val_accuracy: 0.8835\n",
      "Epoch 703/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8456 - val_loss: 0.3635 - val_accuracy: 0.8738\n",
      "Epoch 704/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.8347 - val_loss: 0.3720 - val_accuracy: 0.8738\n",
      "Epoch 705/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.8335 - val_loss: 0.3670 - val_accuracy: 0.8641\n",
      "Epoch 706/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7901 - val_loss: 0.3650 - val_accuracy: 0.8544\n",
      "Epoch 707/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.8323 - val_loss: 0.3834 - val_accuracy: 0.8447\n",
      "Epoch 708/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.8335 - val_loss: 0.3906 - val_accuracy: 0.8447\n",
      "Epoch 709/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.8106 - val_loss: 0.3675 - val_accuracy: 0.8835\n",
      "Epoch 710/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.8227 - val_loss: 0.4082 - val_accuracy: 0.8447\n",
      "Epoch 711/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.8251 - val_loss: 0.4491 - val_accuracy: 0.7961\n",
      "Epoch 712/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.7986 - val_loss: 0.3894 - val_accuracy: 0.8641\n",
      "Epoch 713/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.8432 - val_loss: 0.3676 - val_accuracy: 0.8641\n",
      "Epoch 714/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.8046 - val_loss: 0.4209 - val_accuracy: 0.7961\n",
      "Epoch 715/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.8118 - val_loss: 0.3749 - val_accuracy: 0.8835\n",
      "Epoch 716/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.8106 - val_loss: 0.3997 - val_accuracy: 0.7864\n",
      "Epoch 717/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.8251 - val_loss: 0.5237 - val_accuracy: 0.7670\n",
      "Epoch 718/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.8118 - val_loss: 0.3989 - val_accuracy: 0.8835\n",
      "Epoch 719/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.8070 - val_loss: 0.4033 - val_accuracy: 0.8252\n",
      "Epoch 720/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.8239 - val_loss: 0.4575 - val_accuracy: 0.7864\n",
      "Epoch 721/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.8227 - val_loss: 0.3839 - val_accuracy: 0.8544\n",
      "Epoch 722/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.8287 - val_loss: 0.4010 - val_accuracy: 0.8058\n",
      "Epoch 723/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.8166 - val_loss: 0.4172 - val_accuracy: 0.7864\n",
      "Epoch 724/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.8263 - val_loss: 0.3721 - val_accuracy: 0.8641\n",
      "Epoch 725/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.8227 - val_loss: 0.3696 - val_accuracy: 0.8544\n",
      "Epoch 726/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.8179 - val_loss: 0.3972 - val_accuracy: 0.8835\n",
      "Epoch 727/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.8372 - val_loss: 0.4027 - val_accuracy: 0.8252\n",
      "Epoch 728/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.8275 - val_loss: 0.4115 - val_accuracy: 0.7864\n",
      "Epoch 729/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.8070 - val_loss: 0.3631 - val_accuracy: 0.8641\n",
      "Epoch 730/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.8335 - val_loss: 0.3851 - val_accuracy: 0.8252\n",
      "Epoch 731/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.8347 - val_loss: 0.3961 - val_accuracy: 0.8058\n",
      "Epoch 732/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.8323 - val_loss: 0.3635 - val_accuracy: 0.8738\n",
      "Epoch 733/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.8311 - val_loss: 0.6702 - val_accuracy: 0.6990\n",
      "Epoch 734/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.8022 - val_loss: 0.3760 - val_accuracy: 0.8641\n",
      "Epoch 735/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.8347 - val_loss: 0.3883 - val_accuracy: 0.8641\n",
      "Epoch 736/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.8239 - val_loss: 0.3712 - val_accuracy: 0.8544\n",
      "Epoch 737/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.8227 - val_loss: 0.4471 - val_accuracy: 0.7961\n",
      "Epoch 738/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.8335 - val_loss: 0.3661 - val_accuracy: 0.8447\n",
      "Epoch 739/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.8203 - val_loss: 0.3698 - val_accuracy: 0.8738\n",
      "Epoch 740/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.8359 - val_loss: 0.3789 - val_accuracy: 0.8252\n",
      "Epoch 741/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.8251 - val_loss: 0.3861 - val_accuracy: 0.8252\n",
      "Epoch 742/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8372 - val_loss: 0.3714 - val_accuracy: 0.8252\n",
      "Epoch 743/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.8203 - val_loss: 0.4202 - val_accuracy: 0.7961\n",
      "Epoch 744/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8347 - val_loss: 0.4143 - val_accuracy: 0.8932\n",
      "Epoch 745/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.8082 - val_loss: 0.3549 - val_accuracy: 0.8350\n",
      "Epoch 746/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.8166 - val_loss: 0.3657 - val_accuracy: 0.8835\n",
      "Epoch 747/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.8299 - val_loss: 0.3580 - val_accuracy: 0.8932\n",
      "Epoch 748/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.8239 - val_loss: 0.4450 - val_accuracy: 0.7961\n",
      "Epoch 749/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.8347 - val_loss: 0.3710 - val_accuracy: 0.8447\n",
      "Epoch 750/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.8179 - val_loss: 0.4096 - val_accuracy: 0.8350\n",
      "Epoch 751/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.8166 - val_loss: 0.3466 - val_accuracy: 0.8738\n",
      "Epoch 752/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.8203 - val_loss: 0.3935 - val_accuracy: 0.8252\n",
      "Epoch 753/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.7986 - val_loss: 0.4068 - val_accuracy: 0.7961\n",
      "Epoch 754/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.8396 - val_loss: 0.3873 - val_accuracy: 0.8155\n",
      "Epoch 755/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.8335 - val_loss: 0.3798 - val_accuracy: 0.8641\n",
      "Epoch 756/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.8142 - val_loss: 0.3670 - val_accuracy: 0.8544\n",
      "Epoch 757/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.8275 - val_loss: 0.4420 - val_accuracy: 0.8544\n",
      "Epoch 758/900\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.8335 - val_loss: 0.3588 - val_accuracy: 0.8544\n",
      "Epoch 759/900\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.8215 - val_loss: 0.3497 - val_accuracy: 0.8447\n",
      "Epoch 760/900\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.8396 - val_loss: 0.3441 - val_accuracy: 0.8835\n",
      "Epoch 761/900\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.8275 - val_loss: 0.3947 - val_accuracy: 0.8058\n",
      "Epoch 762/900\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.4998 - accuracy: 0.8106 - val_loss: 0.4205 - val_accuracy: 0.7864\n",
      "Epoch 763/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4205 - accuracy: 0.8299 - val_loss: 0.3654 - val_accuracy: 0.8544\n",
      "Epoch 764/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.8251 - val_loss: 0.4208 - val_accuracy: 0.7961\n",
      "Epoch 765/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.8166 - val_loss: 0.4627 - val_accuracy: 0.7670\n",
      "Epoch 766/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.8251 - val_loss: 0.3741 - val_accuracy: 0.8835\n",
      "Epoch 767/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.8166 - val_loss: 0.4118 - val_accuracy: 0.7864\n",
      "Epoch 768/900\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.8142 - val_loss: 0.3937 - val_accuracy: 0.8350\n",
      "Epoch 769/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.8179 - val_loss: 0.4322 - val_accuracy: 0.8058\n",
      "Epoch 770/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.8275 - val_loss: 0.3663 - val_accuracy: 0.9126\n",
      "Epoch 771/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.8287 - val_loss: 0.4063 - val_accuracy: 0.8932\n",
      "Epoch 772/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.8154 - val_loss: 0.4090 - val_accuracy: 0.8058\n",
      "Epoch 773/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.8335 - val_loss: 0.3579 - val_accuracy: 0.8544\n",
      "Epoch 774/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.8287 - val_loss: 0.3807 - val_accuracy: 0.8641\n",
      "Epoch 775/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.8372 - val_loss: 0.3534 - val_accuracy: 0.8641\n",
      "Epoch 776/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.8166 - val_loss: 0.3676 - val_accuracy: 0.8932\n",
      "Epoch 777/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.8251 - val_loss: 0.4149 - val_accuracy: 0.7961\n",
      "Epoch 778/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.8347 - val_loss: 0.3706 - val_accuracy: 0.8544\n",
      "Epoch 779/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.8275 - val_loss: 0.3548 - val_accuracy: 0.8544\n",
      "Epoch 780/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.8287 - val_loss: 0.3542 - val_accuracy: 0.8641\n",
      "Epoch 781/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4034 - accuracy: 0.8432 - val_loss: 0.3479 - val_accuracy: 0.8738\n",
      "Epoch 782/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.8094 - val_loss: 0.3666 - val_accuracy: 0.8738\n",
      "Epoch 783/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.8203 - val_loss: 0.3580 - val_accuracy: 0.8738\n",
      "Epoch 784/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.8191 - val_loss: 0.3520 - val_accuracy: 0.8738\n",
      "Epoch 785/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.8432 - val_loss: 0.3489 - val_accuracy: 0.8544\n",
      "Epoch 786/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.8239 - val_loss: 0.3437 - val_accuracy: 0.8641\n",
      "Epoch 787/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8384 - val_loss: 0.3443 - val_accuracy: 0.8738\n",
      "Epoch 788/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.8384 - val_loss: 0.3461 - val_accuracy: 0.8738\n",
      "Epoch 789/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.8287 - val_loss: 0.3491 - val_accuracy: 0.8738\n",
      "Epoch 790/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.8323 - val_loss: 0.3850 - val_accuracy: 0.8350\n",
      "Epoch 791/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.8179 - val_loss: 0.3841 - val_accuracy: 0.8350\n",
      "Epoch 792/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.8384 - val_loss: 0.3557 - val_accuracy: 0.8738\n",
      "Epoch 793/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.8384 - val_loss: 0.3639 - val_accuracy: 0.8447\n",
      "Epoch 794/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.8299 - val_loss: 0.3846 - val_accuracy: 0.8350\n",
      "Epoch 795/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.8323 - val_loss: 0.4036 - val_accuracy: 0.8447\n",
      "Epoch 796/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.8323 - val_loss: 0.3454 - val_accuracy: 0.8641\n",
      "Epoch 797/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.8263 - val_loss: 0.5482 - val_accuracy: 0.7670\n",
      "Epoch 798/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.8179 - val_loss: 0.3710 - val_accuracy: 0.8641\n",
      "Epoch 799/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.7660 - val_loss: 0.4060 - val_accuracy: 0.8252\n",
      "Epoch 800/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.8311 - val_loss: 0.3608 - val_accuracy: 0.8641\n",
      "Epoch 801/900\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.8311 - val_loss: 0.3891 - val_accuracy: 0.8447\n",
      "Epoch 802/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.8094 - val_loss: 0.3773 - val_accuracy: 0.8835\n",
      "Epoch 803/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.8251 - val_loss: 0.3559 - val_accuracy: 0.9126\n",
      "Epoch 804/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4205 - accuracy: 0.8215 - val_loss: 0.4378 - val_accuracy: 0.8058\n",
      "Epoch 805/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.8215 - val_loss: 0.3999 - val_accuracy: 0.8447\n",
      "Epoch 806/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.8046 - val_loss: 0.3494 - val_accuracy: 0.8835\n",
      "Epoch 807/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8311 - val_loss: 0.4127 - val_accuracy: 0.8447\n",
      "Epoch 808/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.8420 - val_loss: 0.3573 - val_accuracy: 0.8932\n",
      "Epoch 809/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.8408 - val_loss: 0.4075 - val_accuracy: 0.8058\n",
      "Epoch 810/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.8106 - val_loss: 0.6927 - val_accuracy: 0.6408\n",
      "Epoch 811/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7780 - val_loss: 0.3577 - val_accuracy: 0.8641\n",
      "Epoch 812/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.8396 - val_loss: 0.4130 - val_accuracy: 0.8058\n",
      "Epoch 813/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.8335 - val_loss: 0.4508 - val_accuracy: 0.7961\n",
      "Epoch 814/900\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.4138 - accuracy: 0.8299 - val_loss: 0.3447 - val_accuracy: 0.8932\n",
      "Epoch 815/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.8299 - val_loss: 0.3474 - val_accuracy: 0.9029\n",
      "Epoch 816/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.8299 - val_loss: 0.3669 - val_accuracy: 0.9029\n",
      "Epoch 817/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.8263 - val_loss: 0.3649 - val_accuracy: 0.8544\n",
      "Epoch 818/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.8372 - val_loss: 0.3504 - val_accuracy: 0.8835\n",
      "Epoch 819/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8372 - val_loss: 0.3566 - val_accuracy: 0.8932\n",
      "Epoch 820/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.8335 - val_loss: 0.3715 - val_accuracy: 0.8544\n",
      "Epoch 821/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.8106 - val_loss: 0.3760 - val_accuracy: 0.8932\n",
      "Epoch 822/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.8359 - val_loss: 0.3606 - val_accuracy: 0.9029\n",
      "Epoch 823/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.8251 - val_loss: 0.3822 - val_accuracy: 0.8350\n",
      "Epoch 824/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.8094 - val_loss: 0.4690 - val_accuracy: 0.7864\n",
      "Epoch 825/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.8215 - val_loss: 0.3733 - val_accuracy: 0.8350\n",
      "Epoch 826/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8384 - val_loss: 0.4187 - val_accuracy: 0.8058\n",
      "Epoch 827/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.8359 - val_loss: 0.3816 - val_accuracy: 0.8835\n",
      "Epoch 828/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.8070 - val_loss: 0.3494 - val_accuracy: 0.8738\n",
      "Epoch 829/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.8058 - val_loss: 0.3560 - val_accuracy: 0.8641\n",
      "Epoch 830/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.8179 - val_loss: 0.3535 - val_accuracy: 0.8544\n",
      "Epoch 831/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8408 - val_loss: 0.3661 - val_accuracy: 0.8932\n",
      "Epoch 832/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.8432 - val_loss: 0.3558 - val_accuracy: 0.8932\n",
      "Epoch 833/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.8275 - val_loss: 0.3615 - val_accuracy: 0.8350\n",
      "Epoch 834/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.8287 - val_loss: 0.3473 - val_accuracy: 0.8641\n",
      "Epoch 835/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8239 - val_loss: 0.3808 - val_accuracy: 0.8544\n",
      "Epoch 836/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.8227 - val_loss: 0.3898 - val_accuracy: 0.8350\n",
      "Epoch 837/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.8094 - val_loss: 0.3389 - val_accuracy: 0.8932\n",
      "Epoch 838/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4090 - accuracy: 0.8359 - val_loss: 0.3348 - val_accuracy: 0.9029\n",
      "Epoch 839/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.8179 - val_loss: 0.4856 - val_accuracy: 0.7864\n",
      "Epoch 840/900\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.8106 - val_loss: 0.4042 - val_accuracy: 0.8155\n",
      "Epoch 841/900\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.8408 - val_loss: 0.3470 - val_accuracy: 0.8738\n",
      "Epoch 842/900\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.8094 - val_loss: 0.4908 - val_accuracy: 0.7767\n",
      "Epoch 843/900\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.8034 - val_loss: 0.4948 - val_accuracy: 0.7767\n",
      "Epoch 844/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.8263 - val_loss: 0.3557 - val_accuracy: 0.9029\n",
      "Epoch 845/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.8323 - val_loss: 0.3435 - val_accuracy: 0.8835\n",
      "Epoch 846/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.8287 - val_loss: 0.3577 - val_accuracy: 0.9126\n",
      "Epoch 847/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.8384 - val_loss: 0.3408 - val_accuracy: 0.8738\n",
      "Epoch 848/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.8106 - val_loss: 0.3551 - val_accuracy: 0.8544\n",
      "Epoch 849/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.8142 - val_loss: 0.3567 - val_accuracy: 0.8447\n",
      "Epoch 850/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.8227 - val_loss: 0.3590 - val_accuracy: 0.8835\n",
      "Epoch 851/900\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.4521 - accuracy: 0.8154 - val_loss: 0.3466 - val_accuracy: 0.8738\n",
      "Epoch 852/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.8359 - val_loss: 0.3915 - val_accuracy: 0.8350\n",
      "Epoch 853/900\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.8299 - val_loss: 0.4042 - val_accuracy: 0.8058\n",
      "Epoch 854/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.8287 - val_loss: 0.3512 - val_accuracy: 0.8835\n",
      "Epoch 855/900\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.8251 - val_loss: 0.3480 - val_accuracy: 0.8835\n",
      "Epoch 856/900\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.8335 - val_loss: 0.3911 - val_accuracy: 0.8252\n",
      "Epoch 857/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4058 - accuracy: 0.8347 - val_loss: 0.3301 - val_accuracy: 0.9029\n",
      "Epoch 858/900\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.8191 - val_loss: 0.3544 - val_accuracy: 0.9126\n",
      "Epoch 859/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.8323 - val_loss: 0.3722 - val_accuracy: 0.8350\n",
      "Epoch 860/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.8203 - val_loss: 0.3468 - val_accuracy: 0.8932\n",
      "Epoch 861/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.8287 - val_loss: 0.3537 - val_accuracy: 0.8447\n",
      "Epoch 862/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.8384 - val_loss: 0.3753 - val_accuracy: 0.8641\n",
      "Epoch 863/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.8106 - val_loss: 0.3610 - val_accuracy: 0.8641\n",
      "Epoch 864/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.8239 - val_loss: 0.3609 - val_accuracy: 0.8447\n",
      "Epoch 865/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8287 - val_loss: 0.3849 - val_accuracy: 0.8835\n",
      "Epoch 866/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.8106 - val_loss: 0.4481 - val_accuracy: 0.7864\n",
      "Epoch 867/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.8082 - val_loss: 0.5004 - val_accuracy: 0.7670\n",
      "Epoch 868/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.8263 - val_loss: 0.3448 - val_accuracy: 0.8738\n",
      "Epoch 869/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.8299 - val_loss: 0.4255 - val_accuracy: 0.8058\n",
      "Epoch 870/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.8239 - val_loss: 0.3375 - val_accuracy: 0.8738\n",
      "Epoch 871/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.8046 - val_loss: 0.3432 - val_accuracy: 0.8641\n",
      "Epoch 872/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.8142 - val_loss: 0.3444 - val_accuracy: 0.8835\n",
      "Epoch 873/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.8191 - val_loss: 0.3697 - val_accuracy: 0.8350\n",
      "Epoch 874/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.8287 - val_loss: 0.3710 - val_accuracy: 0.8544\n",
      "Epoch 875/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.8263 - val_loss: 0.3348 - val_accuracy: 0.8835\n",
      "Epoch 876/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.8359 - val_loss: 0.3945 - val_accuracy: 0.8738\n",
      "Epoch 877/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.8239 - val_loss: 0.3699 - val_accuracy: 0.8835\n",
      "Epoch 878/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.8227 - val_loss: 0.3743 - val_accuracy: 0.8447\n",
      "Epoch 879/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.8070 - val_loss: 0.3536 - val_accuracy: 0.8544\n",
      "Epoch 880/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.8191 - val_loss: 0.3444 - val_accuracy: 0.8835\n",
      "Epoch 881/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.8287 - val_loss: 0.3548 - val_accuracy: 0.8641\n",
      "Epoch 882/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.8335 - val_loss: 0.3308 - val_accuracy: 0.8932\n",
      "Epoch 883/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.8191 - val_loss: 0.3352 - val_accuracy: 0.9029\n",
      "Epoch 884/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.8251 - val_loss: 0.3471 - val_accuracy: 0.8544\n",
      "Epoch 885/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4958 - accuracy: 0.7986 - val_loss: 0.3539 - val_accuracy: 0.8447\n",
      "Epoch 886/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.8275 - val_loss: 0.4028 - val_accuracy: 0.9029\n",
      "Epoch 887/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7925 - val_loss: 0.4848 - val_accuracy: 0.7864\n",
      "Epoch 888/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.8227 - val_loss: 0.3854 - val_accuracy: 0.8447\n",
      "Epoch 889/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.8263 - val_loss: 0.3599 - val_accuracy: 0.8447\n",
      "Epoch 890/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.8311 - val_loss: 0.3684 - val_accuracy: 0.8544\n",
      "Epoch 891/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4058 - accuracy: 0.8263 - val_loss: 0.3382 - val_accuracy: 0.8641\n",
      "Epoch 892/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.8215 - val_loss: 0.3684 - val_accuracy: 0.8932\n",
      "Epoch 893/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.8239 - val_loss: 0.3925 - val_accuracy: 0.8155\n",
      "Epoch 894/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.8154 - val_loss: 0.4017 - val_accuracy: 0.8252\n",
      "Epoch 895/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.8227 - val_loss: 0.4074 - val_accuracy: 0.8835\n",
      "Epoch 896/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.8118 - val_loss: 0.3764 - val_accuracy: 0.8447\n",
      "Epoch 897/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.8372 - val_loss: 0.3719 - val_accuracy: 0.8447\n",
      "Epoch 898/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.8275 - val_loss: 0.3508 - val_accuracy: 0.8932\n",
      "Epoch 899/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.8335 - val_loss: 0.3402 - val_accuracy: 0.8641\n",
      "Epoch 900/900\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.4068 - accuracy: 0.8384 - val_loss: 0.3441 - val_accuracy: 0.9126\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3441 - accuracy: 0.9126\n",
      "Test Loss: 0.3440728485584259\n",
      "Test Accuracy: 0.9126213788986206\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dropout\n",
    "from keras import regularizers\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.array(dataset.drop(['target'], 1)) #feature columns from excel file, we have dropped target as it represents the output\n",
    "#1 means axis1 we have dropped the column target\n",
    "y = np.array(dataset['target']) #output is the column target\n",
    "\n",
    "\n",
    "X = X.astype(float) #convert x datatype to float, we may have fractions\n",
    "y = y.astype(int) #convert y to int as we have class labels\n",
    "\n",
    "#stratify=y    y is maintained across the training and testing datasets \n",
    "#This is particularly useful when dealing with imbalanced datasets where the classes have unequal representation.\n",
    "#لانه توزيع ال0 و ال1 للاوتبوت مش متكافئة او مش بنفس العدد\n",
    "# random_state it is often used to control the randomness in data splitting, initialization of model parameters,\n",
    "# convert integer-encoded categorical labels into one-hot encoded vectors. One-hot encoding is a binary representation \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42, test_size=0.1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, stratify=y_train, random_state=42, test_size=0.1)\n",
    "\n",
    "#we can delete this part as our problem is binary classification\n",
    "Y_train = to_categorical(y_train, num_classes=None)\n",
    "Y_val = to_categorical(y_val, num_classes=None)\n",
    "Y_test = to_categorical(y_test, num_classes=None)\n",
    "\n",
    "\n",
    "# define a function to build the keras model\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_dim=13, activation='relu',kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dense(16,  activation='relu',kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dense(8,  activation='relu'))\n",
    "    model.add(Dropout(0.20))\n",
    "    model.add(Dense(2, activation='sigmoid'))\n",
    "    \n",
    "    # compile model\n",
    "    adam = Adam(lr=0.001)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "history=model.fit(X_train, Y_train, validation_data=(X_test, Y_test),epochs=900, batch_size=10)\n",
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1f61ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 75ms/step\n",
      "prediction for new patient [0]\n"
     ]
    }
   ],
   "source": [
    "print(\"prediction for new patient\", np.argmax(model.predict(np.array([[25,1,3,200,233,1,0,120,0,2.3,0,0,2]])),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f21ff38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 53ms/step\n",
      "prediction for new patient [1]\n"
     ]
    }
   ],
   "source": [
    "print(\"prediction for new patient\", np.argmax(model.predict(np.array([[66,0,1,130,236,1,0,174,0,2,1,0,2]])),axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
